# Default values for mcp-server-langgraph
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 2  # Optimized from 3 (-33% base cost)

image:
  repository: ghcr.io/vishnu2kmohan/mcp-server-langgraph
  pullPolicy: IfNotPresent
  tag: "2.8.0"
  # Image variant selection (choose based on deployment needs)
  # Variants:
  #   base (default): 724MB - API-based embeddings, no ML (most deployments)
  #   full:           4.32GB - Includes PyTorch + sentence-transformers (local ML)
  #   test:           880MB - Dev dependencies (CI/CD only)
  variant: "base"  # Options: base, full, test

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  annotations:
    # AWS EKS IRSA
    # eks.amazonaws.com/role-arn: arn:aws:iam::ACCOUNT_ID:role/mcp-server-langgraph-role
    # GKE Workload Identity
    # iam.gke.io/gcp-service-account: mcp-server-langgraph@PROJECT_ID.iam.gserviceaccount.com
    # Azure AKS Workload Identity
    # azure.workload.identity/client-id: "AZURE_CLIENT_ID"
  name: ""

podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "8000"
  prometheus.io/path: "/metrics/prometheus"

podSecurityContext:
  runAsNonRoot: true
  runAsUser: 1000
  fsGroup: 1000
  seccompProfile:
    type: RuntimeDefault

securityContext:
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: true
  runAsNonRoot: true
  runAsUser: 1000
  capabilities:
    drop:
    - ALL

service:
  type: ClusterIP
  port: 80
  targetPort: 8000
  annotations: {}
    # AWS EKS Network Load Balancer
    # service.beta.kubernetes.io/aws-load-balancer-type: "nlb"
    # GKE
    # cloud.google.com/neg: '{"ingress": true}'

ingress:
  enabled: false
  className: "nginx"
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    # For AWS ALB
    # kubernetes.io/ingress.class: alb
    # alb.ingress.kubernetes.io/scheme: internet-facing
    # alb.ingress.kubernetes.io/target-type: ip
  hosts:
    - host: mcp-server-langgraph.example.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: mcp-server-langgraph-tls
      hosts:
        - mcp-server-langgraph.example.com

resources:
  # Optimized resource allocation (70% cost reduction)
  limits:
    cpu: 1000m       # Was: 2000m (-50%)
    memory: 1Gi      # Was: 2Gi (-50%)
  requests:
    cpu: 250m        # Was: 500m (-50%)
    memory: 384Mi    # Was: 512Mi (-25%)

autoscaling:
  enabled: true
  minReplicas: 2                         # Was: 3 (-33% base cost)
  maxReplicas: 20                        # Was: 10 (+100% burst capacity)
  targetCPUUtilizationPercentage: 60     # Was: 70 (more responsive)
  targetMemoryUtilizationPercentage: 70  # Was: 80 (safer buffer)
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
        - type: Percent
          value: 50
          periodSeconds: 60
        - type: Pods
          value: 2
          periodSeconds: 60
      selectPolicy: Min
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
        - type: Percent
          value: 100
          periodSeconds: 30
        - type: Pods
          value: 4
          periodSeconds: 30
      selectPolicy: Max

nodeSelector: {}

tolerations:
  - key: "workload"
    operator: "Equal"
    value: "ai-agents"
    effect: "NoSchedule"

affinity:
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
              - key: app.kubernetes.io/name
                operator: In
                values:
                  - mcp-server-langgraph
          topologyKey: kubernetes.io/hostname

# Pod Disruption Budget
podDisruptionBudget:
  enabled: true
  minAvailable: 2

# Network Policy
networkPolicy:
  enabled: true
  policyTypes:
    - Ingress
    - Egress

# Health checks
healthChecks:
  startup:
    path: /health/startup
    initialDelaySeconds: 10
    periodSeconds: 5
    timeoutSeconds: 3
    failureThreshold: 30
  liveness:
    path: /health
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3
  readiness:
    path: /health/ready
    initialDelaySeconds: 20
    periodSeconds: 5
    timeoutSeconds: 3
    failureThreshold: 3

# Application configuration
config:
  serviceName: "mcp-server-langgraph"
  environment: "production"
  logLevel: "INFO"

  # LLM Configuration
  llmProvider: "anthropic"  # google, anthropic, openai, azure, bedrock, ollama
  modelName: "claude-sonnet-4-5"
  modelTemperature: "0.7"
  modelMaxTokens: "4096"
  modelTimeout: "60"
  enableFallback: "true"

  # Agent Configuration
  maxIterations: "10"
  enableCheckpointing: "true"

  # Observability
  enableTracing: "true"
  enableMetrics: "true"
  enableConsoleExport: "false"
  observabilityBackend: "opentelemetry"  # opentelemetry, langsmith, both
  langsmithTracing: "false"

  # Authentication
  authProvider: "keycloak"  # inmemory, keycloak
  authMode: "token"  # token (JWT), session

  # Keycloak Configuration
  keycloakServerUrl: "http://keycloak:8080"
  keycloakRealm: "mcp-server-langgraph"
  keycloakClientId: "langgraph-client"
  keycloakVerifySsl: "true"
  keycloakTimeout: "30"
  keycloakHostname: "mcp-server-langgraph.example.com"

  # Session Management
  sessionBackend: "redis"  # memory, redis
  redisUrl: "redis://redis-session:6379/0"
  redisSsl: "false"
  sessionTtlSeconds: "86400"  # 24 hours
  sessionSlidingWindow: "true"
  sessionMaxConcurrent: "5"

  # Agentic Loop Configuration (Anthropic Best Practices)
  # Context Management - Implements "Compaction" technique
  enableContextCompaction: "true"
  compactionThreshold: "8000"  # Token count that triggers compaction
  targetAfterCompaction: "4000"  # Target tokens after compaction
  recentMessageCount: "5"  # Number of recent messages to keep uncompacted

  # Work Verification - Implements "LLM-as-Judge" pattern
  enableVerification: "true"
  verificationQualityThreshold: "0.7"  # Minimum quality score (0.0-1.0)
  maxRefinementAttempts: "3"  # Maximum refinement iterations
  verificationMode: "standard"  # strict, standard, lenient

  # Dynamic Context Loading (Just-in-Time) - Requires Qdrant
  enableDynamicContextLoading: "false"  # Enable semantic search-based context
  qdrantUrl: "qdrant"  # Qdrant service name
  qdrantPort: "6333"  # Qdrant HTTP API port
  qdrantCollectionName: "mcp_context"  # Collection for context storage
  dynamicContextMaxTokens: "2000"  # Max tokens from dynamic context
  dynamicContextTopK: "3"  # Top semantic search results
  embeddingModel: "all-MiniLM-L6-v2"  # SentenceTransformer model
  contextCacheSize: "100"  # LRU cache size for contexts

  # Parallel Tool Execution - Performance Optimization
  enableParallelExecution: "false"
  maxParallelTools: "5"  # Maximum concurrent tool executions

  # Enhanced Note-Taking - Structured Information Extraction
  enableLlmExtraction: "false"  # Use LLM for note extraction

  # Conversation Checkpointing (Distributed State)
  checkpointBackend: "redis"  # memory or redis (use redis for production)
  checkpointRedisUrl: "redis://redis-session:6379/1"  # Use db 1
  checkpointRedisTtl: "604800"  # 7 days TTL for conversation checkpoints

# Secrets configuration
secrets:
  # Use existingSecret to reference an existing secret
  existingSecret: ""

  # Or provide secrets here (NOT recommended for production)
  # Use External Secrets Operator or cloud-native secret management instead

  # LLM Provider API Keys
  anthropicApiKey: ""
  googleApiKey: ""
  openaiApiKey: ""

  # Authentication & Authorization
  jwtSecretKey: ""
  openfgaStoreId: ""
  openfgaModelId: ""

  # Keycloak
  keycloakClientSecret: ""
  keycloakAdminUsername: "admin"
  keycloakAdminPassword: ""

  # PostgreSQL
  postgresUsername: "postgres"
  postgresPassword: ""

  # Redis
  redisPassword: ""

  # Secrets Management (optional)
  infisicalClientId: ""
  infisicalClientSecret: ""
  infisicalProjectId: ""

  # LangSmith (optional)
  langsmithApiKey: ""

# External Secrets Operator integration
externalSecrets:
  enabled: false
  refreshInterval: 1h
  secretStoreRef:
    name: aws-secrets-manager  # or azure-key-vault, gcp-secret-manager, vault
    kind: SecretStore
  data:
    - secretKey: anthropic-api-key
      remoteRef:
        key: mcp-server-langgraph/anthropic-api-key
    - secretKey: jwt-secret-key
      remoteRef:
        key: mcp-server-langgraph/jwt-secret-key
    - secretKey: openfga-store-id
      remoteRef:
        key: mcp-server-langgraph/openfga-store-id
    - secretKey: openfga-model-id
      remoteRef:
        key: mcp-server-langgraph/openfga-model-id

# OpenFGA dependency
openfga:
  postgresql:
    enabled: true
  service:
    type: ClusterIP
    port: 8080

# PostgreSQL dependency (shared by OpenFGA and Keycloak)
postgresql:
  enabled: true
  auth:
    username: postgres
    password: postgres
    # Multiple databases will be created via initdb scripts
    database: postgres
  primary:
    initdb:
      scripts:
        init-databases.sql: |
          -- Create separate databases for OpenFGA and Keycloak
          CREATE DATABASE openfga;
          CREATE DATABASE keycloak;
    persistence:
      enabled: true
      size: 10Gi
    resources:
      requests:
        cpu: 250m
        memory: 256Mi
      limits:
        cpu: 1000m
        memory: 1Gi

# Redis dependency (for session management)
redis:
  enabled: true
  architecture: standalone
  auth:
    enabled: true
    password: redis
  master:
    persistence:
      enabled: true
      size: 5Gi
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 500m
        memory: 1Gi

# Keycloak dependency (for SSO/authentication)
keycloak:
  enabled: true
  replicas: 2
  postgresql:
    enabled: false  # Use shared PostgreSQL instance above
  externalDatabase:
    host: postgresql
    port: 5432
    database: keycloak
    user: postgres
    existingSecret: ""
    existingSecretPasswordKey: postgres-password
  auth:
    adminUser: admin
    existingSecret: ""
    passwordSecretKey: keycloak-admin-password
  service:
    type: ClusterIP
    port: 8080
  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: 2000m
      memory: 2Gi

# Jaeger dependency (for distributed tracing)
jaeger:
  enabled: true
  provisionDataStore:
    cassandra: false
  allInOne:
    enabled: true
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 500m
        memory: 512Mi
  storage:
    type: none  # Use in-memory storage for simplicity
  agent:
    enabled: false  # Not needed with allInOne
  collector:
    enabled: false  # Not needed with allInOne
  query:
    enabled: false  # Not needed with allInOne
  service:
    type: ClusterIP
    # UI port
    query:
      port: 16686
    # Collector ports
    collector:
      http:
        port: 14268
      grpc:
        port: 14250
      zipkin:
        port: 9411

# Kube Prometheus Stack (Prometheus + AlertManager + Grafana)
# Note: This includes its own Grafana, but we're using Bitnami Grafana above
kube-prometheus-stack:
  enabled: true

  # Disable the built-in Grafana since we're using Bitnami Grafana
  grafana:
    enabled: false

  # Prometheus configuration
  prometheus:
    enabled: true
    prometheusSpec:
      retention: 30d
      resources:
        requests:
          cpu: 200m
          memory: 512Mi
        limits:
          cpu: 1000m
          memory: 2Gi
      storageSpec:
        volumeClaimTemplate:
          spec:
            accessModes: ["ReadWriteOnce"]
            resources:
              requests:
                storage: 50Gi
      # Service monitors
      serviceMonitorSelectorNilUsesHelmValues: false
      podMonitorSelectorNilUsesHelmValues: false
      ruleSelectorNilUsesHelmValues: false

  # AlertManager configuration
  alertmanager:
    enabled: true
    config:
      global:
        resolve_timeout: 5m
      route:
        receiver: 'default'
        group_by: ['alertname', 'severity', 'component']
        group_wait: 10s
        group_interval: 10s
        repeat_interval: 12h
        routes:
          - match:
              severity: critical
            receiver: slack-critical
            group_wait: 0s
            repeat_interval: 4h
          - match:
              severity: warning
            receiver: slack-warnings
            repeat_interval: 12h
          - match:
              severity: info
            receiver: email
            repeat_interval: 24h
      receivers:
        - name: 'default'
          webhook_configs:
            - url: 'http://localhost:5001/webhook'
        - name: 'slack-critical'
          slack_configs:
            - api_url: '<YOUR_SLACK_WEBHOOK_URL>'
              channel: '#alerts-critical'
              title: 'Critical Alert: {{ .GroupLabels.alertname }}'
              text: '{{ .CommonAnnotations.summary }}'
        - name: 'slack-warnings'
          slack_configs:
            - api_url: '<YOUR_SLACK_WEBHOOK_URL>'
              channel: '#alerts-warnings'
              title: 'Warning: {{ .GroupLabels.alertname }}'
        - name: 'email'
          email_configs:
            - to: 'team@example.com'
              from: 'alerts@example.com'
    alertmanagerSpec:
      resources:
        requests:
          cpu: 50m
          memory: 128Mi
        limits:
          cpu: 200m
          memory: 256Mi
      storage:
        volumeClaimTemplate:
          spec:
            accessModes: ["ReadWriteOnce"]
            resources:
              requests:
                storage: 10Gi

  # Prometheus Operator
  prometheusOperator:
    enabled: true
    resources:
      requests:
        cpu: 50m
        memory: 128Mi
      limits:
        cpu: 200m
        memory: 256Mi

# Grafana dependency (for dashboards and visualization)
grafana:
  enabled: true
  admin:
    user: admin
    password: admin
  service:
    type: ClusterIP
    port: 80
  # Dashboard provisioning
  dashboardsProvider:
    enabled: true
  dashboardsConfigMaps:
    - configMapName: grafana-dashboards
      fileName: authentication.json
    - configMapName: grafana-dashboards
      fileName: keycloak.json
    - configMapName: grafana-dashboards
      fileName: langgraph-agent.json
    - configMapName: grafana-dashboards
      fileName: llm-performance.json
    - configMapName: grafana-dashboards
      fileName: openfga.json
    - configMapName: grafana-dashboards
      fileName: redis-sessions.json
    - configMapName: grafana-dashboards
      fileName: security.json
    - configMapName: grafana-dashboards
      fileName: sla-monitoring.json
    - configMapName: grafana-dashboards
      fileName: soc2-compliance.json
  # Datasource configuration
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Prometheus
          type: prometheus
          access: proxy
          url: http://{{ .Release.Name }}-kube-prometheus-stack-prometheus:9090
          isDefault: true
          editable: true
        - name: Jaeger
          type: jaeger
          access: proxy
          url: http://{{ .Release.Name }}-jaeger-query:16686
          editable: true
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 500m
      memory: 512Mi

# Service Mesh (Istio/Linkerd)
serviceMesh:
  enabled: false
  istio:
    gateway:
      enabled: false
    virtualService:
      enabled: false

# Monitoring
monitoring:
  enabled: true
  serviceMonitor:
    enabled: true
    interval: 30s
    scrapeTimeout: 10s

# Kong API Gateway integration
kong:
  enabled: false
  # Hosts for Kong ingress
  hosts:
    - mcp-server-langgraph.example.com
  # Path configuration
  path: /
  pathType: Prefix
  # Strip path prefix
  stripPath: "false"
  # Preserve host header
  preserveHost: "true"
  # Protocols
  protocols:
    - https
    - http
  # Timeouts (milliseconds)
  timeouts:
    connect: 60000
    read: 300000
    write: 300000
  # TLS configuration
  tls:
    enabled: true
    secretName: mcp-server-langgraph-tls
  # Kong plugins to apply
  plugins:
    - rate-limit-basic
    - request-size-limit
    - cors
    - prometheus
  # Additional annotations
  annotations: {}
  # Rate limiting tier
  rateLimitTier: basic  # basic, premium, enterprise
