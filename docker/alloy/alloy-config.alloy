// Grafana Alloy Configuration for MCP Server LangGraph Test Environment
// ======================================================================
// Unified telemetry collector replacing Prometheus, Promtail, and OTEL Collector.
// Collects metrics, logs, and forwards them to Mimir and Loki respectively.
//
// Reference: https://grafana.com/docs/alloy/latest/
//
// IMPORTANT: This configuration is for testing only.
// Production deployments should use more robust configurations.

// =============================================================================
// LOGGING CONFIGURATION
// =============================================================================

logging {
  level  = "warn"
  format = "logfmt"
}

// =============================================================================
// METRICS COLLECTION (replaces Prometheus)
// =============================================================================

// Prometheus scrape configuration for all services
prometheus.scrape "services" {
  targets = [
    // MCP Server
    {"__address__" = "mcp-server:8000", "job" = "mcp-server", "service" = "mcp-server"},
    // Builder
    {"__address__" = "builder:8001", "job" = "builder", "service" = "builder"},
    // Playground
    {"__address__" = "playground:8002", "job" = "playground", "service" = "playground"},
    // Keycloak (metrics on management port)
    {"__address__" = "keycloak:9000", "job" = "keycloak", "service" = "keycloak"},
    // Redis (via redis_exporter if available, otherwise skip)
    // {"__address__" = "redis:6379", "job" = "redis", "service" = "redis"},
  ]

  forward_to = [prometheus.remote_write.mimir.receiver]

  scrape_interval = "15s"
  scrape_timeout  = "10s"

  // Add common labels
  clustering {
    enabled = false
  }
}

// Scrape Alloy's own metrics
prometheus.scrape "alloy_self" {
  targets = [
    {"__address__" = "localhost:12345", "job" = "alloy"},
  ]

  forward_to = [prometheus.remote_write.mimir.receiver]

  scrape_interval = "30s"
}

// Remote write to Mimir for long-term storage
prometheus.remote_write "mimir" {
  endpoint {
    url = "http://mimir:9009/api/v1/push"

    // Retry configuration for reliability
    queue_config {
      capacity          = 10000
      max_shards        = 5
      max_samples_per_send = 500
    }
  }
}

// =============================================================================
// LOG COLLECTION (replaces Promtail)
// =============================================================================

// Docker log discovery
discovery.docker "containers" {
  host = "unix:///var/run/docker.sock"

  // Filter to only collect logs from mcp-test-network containers
  filter {
    name   = "network"
    values = ["mcp-test-network"]
  }
}

// Relabel discovered containers
discovery.relabel "docker_logs" {
  targets = discovery.docker.containers.targets

  // Use container name as job label
  rule {
    source_labels = ["__meta_docker_container_name"]
    regex         = "/(.*)"
    target_label  = "container"
  }

  // Add service label from container name
  rule {
    source_labels = ["__meta_docker_container_name"]
    regex         = "/([^_]+).*"
    target_label  = "service"
  }

  // Add compose service label if available
  rule {
    source_labels = ["__meta_docker_container_label_com_docker_compose_service"]
    target_label  = "compose_service"
  }

  // Add environment label
  rule {
    replacement  = "test"
    target_label = "environment"
  }
}

// Collect logs from Docker containers
loki.source.docker "containers" {
  host    = "unix:///var/run/docker.sock"
  targets = discovery.relabel.docker_logs.output

  forward_to = [loki.process.docker_logs.receiver]

  // Refresh container list every 5 seconds
  refresh_interval = "5s"
}

// Process logs before sending to Loki
loki.process "docker_logs" {
  forward_to = [loki.write.loki.receiver]

  // Parse JSON logs if present
  stage.json {
    expressions = {
      level   = "level",
      message = "message",
      time    = "timestamp",
    }
  }

  // Add structured metadata
  stage.labels {
    values = {
      level = "",
    }
  }

  // Drop debug logs in test environment to reduce noise
  stage.match {
    selector = "{level=\"debug\"}"
    action   = "drop"
  }
}

// Write logs to Loki
loki.write "loki" {
  endpoint {
    url = "http://loki:3100/loki/api/v1/push"
  }
}

// =============================================================================
// OTLP RECEIVER (for applications sending traces/metrics directly)
// =============================================================================

// Receive OTLP data from applications
otelcol.receiver.otlp "default" {
  grpc {
    endpoint = "0.0.0.0:4317"
  }
  http {
    endpoint = "0.0.0.0:4318"
  }

  output {
    metrics = [otelcol.processor.batch.default.input]
    traces  = [otelcol.processor.batch.default.input]
  }
}

// Batch processor for efficiency
otelcol.processor.batch "default" {
  timeout = "5s"
  send_batch_size = 1000

  output {
    metrics = [otelcol.exporter.prometheus.mimir.input]
    traces  = [otelcol.exporter.otlp.tempo.input]
  }
}

// Export OTLP metrics to Prometheus format for Mimir
otelcol.exporter.prometheus "mimir" {
  forward_to = [prometheus.remote_write.mimir.receiver]
}

// Export traces to Tempo
otelcol.exporter.otlp "tempo" {
  client {
    endpoint = "tempo:4317"
    tls {
      insecure = true
    }
  }
}
