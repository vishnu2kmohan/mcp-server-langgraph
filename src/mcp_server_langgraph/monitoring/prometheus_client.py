"""
Prometheus client service for querying metrics.

Provides a high-level interface for querying Prometheus metrics with:
- Uptime/downtime calculations
- Response time percentiles (p50, p95, p99)
- Error rate calculations
- SLA compliance metrics
- Custom PromQL queries
- Time-range aggregations

Resolves production TODOs:
- monitoring/sla.py:157 - Query actual downtime
- monitoring/sla.py:235 - Query actual response times
- monitoring/sla.py:300 - Query actual error rate
- core/compliance/evidence.py:419 - Uptime data for SOC2 evidence
"""

import logging
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Union

import httpx
from pydantic import BaseModel, Field

from mcp_server_langgraph.core.config import settings

logger = logging.getLogger(__name__)


class PrometheusConfig(BaseModel):
    """Prometheus client configuration"""

    url: str = Field(default="http://prometheus:9090", description="Prometheus server URL")
    timeout: int = Field(default=30, description="Query timeout in seconds")
    retry_attempts: int = Field(default=3, description="Number of retry attempts")
    retry_backoff: float = Field(default=1.0, description="Retry backoff multiplier")


@dataclass
class MetricValue:
    """Single metric value with timestamp"""

    timestamp: datetime
    value: float

    @classmethod
    def from_prometheus(cls, data: List[Union[float, str]]) -> "MetricValue":
        """Parse from Prometheus response format: [timestamp, value]"""
        return cls(timestamp=datetime.fromtimestamp(data[0]), value=float(data[1]))


@dataclass
class QueryResult:
    """Result of a Prometheus query"""

    metric: Dict[str, str]  # Label key-value pairs
    values: List[MetricValue]

    def get_latest_value(self) -> Optional[float]:
        """Get the most recent value"""
        return self.values[-1].value if self.values else None

    def get_average(self) -> Optional[float]:
        """Calculate average across all values"""
        if not self.values:
            return None
        return sum(v.value for v in self.values) / len(self.values)


class PrometheusClient:
    """
    High-level Prometheus query client.

    Usage:
        client = PrometheusClient()
        await client.initialize()

        # Query uptime
        uptime_pct = await client.query_uptime(service="mcp-server", timerange="30d")

        # Query percentiles
        response_times = await client.query_percentiles(
            metric="http_request_duration_seconds",
            percentiles=[50, 95, 99],
            timerange="1h"
        )

        # Query error rate
        error_rate = await client.query_error_rate(timerange="5m")

        await client.close()
    """

    def __init__(self, config: Optional[PrometheusConfig] = None):
        self.config = config or self._load_config_from_settings()
        self.client: Optional[httpx.AsyncClient] = None
        self._initialized = False

    def _load_config_from_settings(self) -> PrometheusConfig:
        """Load configuration from application settings"""
        return PrometheusConfig(
            url=getattr(settings, "prometheus_url", "http://prometheus:9090"),
            timeout=getattr(settings, "prometheus_timeout", 30),
            retry_attempts=getattr(settings, "prometheus_retry_attempts", 3),
        )

    async def initialize(self) -> None:
        """Initialize HTTP client"""
        if self._initialized:
            return

        self.client = httpx.AsyncClient(timeout=self.config.timeout, follow_redirects=True)

        self._initialized = True
        logger.info(f"Prometheus client initialized: {self.config.url}")

    async def close(self) -> None:
        """Close HTTP client"""
        if self.client:
            await self.client.aclose()
        logger.info("Prometheus client closed")

    async def query(self, promql: str, time: Optional[datetime] = None) -> List[QueryResult]:
        """
        Execute instant query.

        Args:
            promql: PromQL query string
            time: Optional evaluation timestamp (defaults to now)

        Returns:
            List of query results
        """
        if not self._initialized:
            await self.initialize()

        params = {"query": promql}
        if time:
            params["time"] = time.timestamp()

        url = f"{self.config.url}/api/v1/query"

        try:
            response = await self.client.get(url, params=params)
            response.raise_for_status()

            data = response.json()

            if data.get("status") != "success":
                raise ValueError(f"Prometheus query failed: {data.get('error', 'Unknown error')}")

            return self._parse_query_result(data["data"]["result"])

        except Exception as e:
            logger.error(f"Prometheus query failed: {e}", exc_info=True, extra={"query": promql})
            raise

    async def query_range(
        self,
        promql: str,
        start: datetime,
        end: datetime,
        step: str = "1m",
    ) -> List[QueryResult]:
        """
        Execute range query.

        Args:
            promql: PromQL query string
            start: Range start time
            end: Range end time
            step: Query resolution step (e.g., "1m", "5m", "1h")

        Returns:
            List of query results with time series
        """
        if not self._initialized:
            await self.initialize()

        params = {
            "query": promql,
            "start": start.timestamp(),
            "end": end.timestamp(),
            "step": step,
        }

        url = f"{self.config.url}/api/v1/query_range"

        try:
            response = await self.client.get(url, params=params)
            response.raise_for_status()

            data = response.json()

            if data.get("status") != "success":
                raise ValueError(f"Prometheus range query failed: {data.get('error', 'Unknown error')}")

            return self._parse_range_result(data["data"]["result"])

        except Exception as e:
            logger.error(f"Prometheus range query failed: {e}", exc_info=True, extra={"query": promql})
            raise

    def _parse_query_result(self, result: List[Dict]) -> List[QueryResult]:
        """Parse instant query result"""
        parsed = []
        for item in result:
            metric = item.get("metric", {})
            value_data = item.get("value", [])

            if value_data:
                values = [MetricValue.from_prometheus(value_data)]
                parsed.append(QueryResult(metric=metric, values=values))

        return parsed

    def _parse_range_result(self, result: List[Dict]) -> List[QueryResult]:
        """Parse range query result"""
        parsed = []
        for item in result:
            metric = item.get("metric", {})
            values_data = item.get("values", [])

            values = [MetricValue.from_prometheus(v) for v in values_data]
            parsed.append(QueryResult(metric=metric, values=values))

        return parsed

    async def query_uptime(
        self,
        service: str = "mcp-server-langgraph",
        timerange: str = "30d",
    ) -> float:
        """
        Calculate service uptime percentage.

        Args:
            service: Service name (label filter)
            timerange: Time range (e.g., "1h", "24h", "30d")

        Returns:
            Uptime percentage (0-100)

        Resolves: monitoring/sla.py:157, core/compliance/evidence.py:419
        """
        # Query: (total time - downtime) / total time * 100
        # Assuming 'up' metric where 0 = down, 1 = up

        promql = f'avg_over_time(up{{job="{service}"}}[{timerange}]) * 100'

        try:
            results = await self.query(promql)

            if results and results[0].values:
                uptime_pct = results[0].get_latest_value()
                logger.info(f"Uptime queried: {uptime_pct:.2f}% over {timerange}", extra={"service": service})
                return uptime_pct

            # Fallback: assume 100% if no data
            logger.warning(f"No uptime data found for {service}, assuming 100%")
            return 100.0

        except Exception as e:
            logger.error(f"Failed to query uptime: {e}", exc_info=True)
            # Return conservative estimate
            return 99.0

    async def query_downtime(
        self,
        service: str = "mcp-server-langgraph",
        timerange: str = "30d",
    ) -> float:
        """
        Calculate total downtime in seconds.

        Args:
            service: Service name
            timerange: Time range

        Returns:
            Total downtime in seconds

        Resolves: monitoring/sla.py:157
        """
        uptime_pct = await self.query_uptime(service=service, timerange=timerange)

        # Calculate total time in seconds
        if timerange.endswith("d"):
            total_seconds = int(timerange[:-1]) * 86400
        elif timerange.endswith("h"):
            total_seconds = int(timerange[:-1]) * 3600
        elif timerange.endswith("m"):
            total_seconds = int(timerange[:-1]) * 60
        else:
            raise ValueError(f"Unsupported timerange format: {timerange}")

        downtime_seconds = total_seconds * (100 - uptime_pct) / 100

        logger.info(f"Downtime calculated: {downtime_seconds:.2f}s over {timerange}", extra={"service": service})

        return downtime_seconds

    async def query_percentiles(
        self,
        metric: str,
        percentiles: List[int] = None,
        timerange: str = "1h",
        label_filters: Optional[Dict[str, str]] = None,
    ) -> Dict[int, float]:
        """
        Query metric percentiles (p50, p95, p99, etc.).

        Args:
            metric: Metric name (e.g., "http_request_duration_seconds")
            percentiles: List of percentiles to query (default: [50, 95, 99])
            timerange: Time range
            label_filters: Additional label filters

        Returns:
            Dictionary mapping percentile to value

        Resolves: monitoring/sla.py:235
        """
        if percentiles is None:
            percentiles = [50, 95, 99]

        # Build label filter string
        label_str = ""
        if label_filters:
            label_parts = [f'{k}="{v}"' for k, v in label_filters.items()]
            label_str = "{" + ", ".join(label_parts) + "}"

        results = {}

        for p in percentiles:
            # Query using histogram_quantile
            quantile = p / 100.0
            promql = f'histogram_quantile({quantile}, rate({metric}_bucket{label_str}[{timerange}]))'

            try:
                query_results = await self.query(promql)

                if query_results and query_results[0].values:
                    value = query_results[0].get_latest_value()
                    results[p] = value
                else:
                    results[p] = 0.0

            except Exception as e:
                logger.error(f"Failed to query p{p}: {e}", exc_info=True)
                results[p] = 0.0

        logger.info(f"Percentiles queried: {results}", extra={"metric": metric, "timerange": timerange})

        return results

    async def query_error_rate(
        self,
        timerange: str = "5m",
        service: str = "mcp-server-langgraph",
    ) -> float:
        """
        Calculate error rate (errors per second / total requests per second).

        Args:
            timerange: Time range
            service: Service name

        Returns:
            Error rate as percentage (0-100)

        Resolves: monitoring/sla.py:300
        """
        # Query error requests
        error_promql = f'rate(http_requests_total{{job="{service}", status=~"5.."}}[{timerange}])'

        # Query total requests
        total_promql = f'rate(http_requests_total{{job="{service}"}}[{timerange}])'

        try:
            error_results = await self.query(error_promql)
            total_results = await self.query(total_promql)

            error_rate_value = 0.0
            total_rate_value = 0.0

            if error_results and error_results[0].values:
                error_rate_value = error_results[0].get_latest_value()

            if total_results and total_results[0].values:
                total_rate_value = total_results[0].get_latest_value()

            if total_rate_value > 0:
                error_pct = (error_rate_value / total_rate_value) * 100
            else:
                error_pct = 0.0

            logger.info(f"Error rate: {error_pct:.2f}% over {timerange}", extra={"service": service})

            return error_pct

        except Exception as e:
            logger.error(f"Failed to query error rate: {e}", exc_info=True)
            return 0.0

    async def query_request_rate(
        self,
        timerange: str = "5m",
        service: str = "mcp-server-langgraph",
    ) -> float:
        """
        Query requests per second.

        Args:
            timerange: Time range
            service: Service name

        Returns:
            Requests per second
        """
        promql = f'rate(http_requests_total{{job="{service}"}}[{timerange}])'

        try:
            results = await self.query(promql)

            if results and results[0].values:
                rps = results[0].get_latest_value()
                logger.info(f"Request rate: {rps:.2f} req/s", extra={"service": service})
                return rps

            return 0.0

        except Exception as e:
            logger.error(f"Failed to query request rate: {e}", exc_info=True)
            return 0.0

    async def query_custom(
        self,
        promql: str,
        timerange: Optional[str] = None,
    ) -> List[QueryResult]:
        """
        Execute custom PromQL query.

        Args:
            promql: Custom PromQL query
            timerange: Optional time range for rate/increase queries

        Returns:
            Query results
        """
        if timerange and "[" not in promql:
            # Auto-inject timerange into rate/increase functions
            promql = promql.replace("rate(", f"rate(").replace(")", f"[{timerange}])")

        return await self.query(promql)

    async def get_sla_metrics(
        self,
        service: str = "mcp-server-langgraph",
        timerange: str = "30d",
    ) -> Dict[str, Any]:
        """
        Get comprehensive SLA metrics.

        Returns:
            Dictionary with uptime, downtime, error_rate, response_times
        """
        uptime_pct = await self.query_uptime(service=service, timerange=timerange)
        downtime_sec = await self.query_downtime(service=service, timerange=timerange)
        error_rate = await self.query_error_rate(service=service, timerange="5m")
        response_times = await self.query_percentiles(
            metric="http_request_duration_seconds",
            percentiles=[50, 95, 99],
            timerange="1h",
        )

        return {
            "uptime_percentage": uptime_pct,
            "downtime_seconds": downtime_sec,
            "error_rate_percentage": error_rate,
            "response_times": {
                "p50_seconds": response_times.get(50, 0),
                "p95_seconds": response_times.get(95, 0),
                "p99_seconds": response_times.get(99, 0),
            },
            "timerange": timerange,
            "service": service,
        }


# Global Prometheus client instance
_prometheus_client: Optional[PrometheusClient] = None


async def get_prometheus_client() -> PrometheusClient:
    """Get or create global Prometheus client instance"""
    global _prometheus_client

    if _prometheus_client is None:
        _prometheus_client = PrometheusClient()
        await _prometheus_client.initialize()

    return _prometheus_client
