---
title: Developer Setup Guide
description: 'Complete guide for setting up your local development environment. - [Quick Start](#quick-start) - [Detailed Setup](#detailed-setup)'
icon: 'code'
seoTitle: "Developer Setup Guide - Developer Reference"
seoDescription: "Development guide: Complete guide for setting up your local development environment. - [Quick Start](#quick-start) - [Detailed Setup](#detailed-setup)"
keywords: ["development", "developer tools", "CI/CD", "build tools"]
contentType: "reference"
---


Complete guide for setting up your local development environment.

### Table of Contents

- [Quick Start](#quick-start)
- [Detailed Setup](#detailed-setup)
- [Development Workflow](#development-workflow)
- [Testing](#testing)
- [Debugging](#debugging)
- [Troubleshooting](#troubleshooting)

---

### Quick Start

Get up and running in 5 minutes:

```bash
## 1. Clone the repository
git clone https://github.com/vishnu2kmohan/mcp-server-langgraph.git
cd mcp_server_langgraph

## 2. Install dependencies (uv sync creates .venv automatically)
uv sync

## 3. Copy environment file
cp .env.example .env

## 4. Get an API key (choose one)
## - Google Gemini: https://aistudio.google.com/apikey (FREE)
## - Anthropic: https://console.anthropic.com/
## - OpenAI: https://platform.openai.com/

## 5. Edit .env and add your API key
echo "GOOGLE_API_KEY=your-api-key-here" >> .env

## 6. Start infrastructure
docker compose up -d

## 7. Setup OpenFGA
uv run python scripts/setup_openfga.py

## 8. Run tests
uv run pytest -m unit -v

## 9. Test the agent
uv run python examples/client_stdio.py
```

**You're ready to develop!** ðŸš€

---

### Detailed Setup

#### Prerequisites

##### Required

- **Python 3.10+** (3.11+ recommended)
  - Check: `python --version`
  - Install: [python.org](https://www.python.org/downloads/)

- **Git**
  - Check: `git --version`
  - Install: [git-scm.com](https://git-scm.com/)

- **Docker & Docker Compose**
  - Check: `docker --version && docker-compose --version`
  - Install: [docker.com](https://www.docker.com/get-started)

##### Optional (for advanced features)

- **kubectl** - For Kubernetes development
  - Install: [kubernetes.io](https://kubernetes.io/docs/tasks/tools/)

- **Helm 3+** - For Helm chart development
  - Install: [helm.sh](https://helm.sh/docs/intro/install/)

- **Make** - For convenience commands
  - Linux/Mac: Usually pre-installed
  - Windows: Install via [Chocolatey](https://chocolatey.org/) or use Git Bash

#### Installation Steps

##### 1. Fork and Clone

```bash
## Fork the repository on GitHub first, then:
git clone https://github.com/YOUR_USERNAME/mcp_server_langgraph.git
cd mcp_server_langgraph

## Add upstream remote
git remote add upstream https://github.com/vishnu2kmohan/mcp-server-langgraph.git

## Verify remotes
git remote -v
```

##### 2. Install Dependencies

<Note>
  **No manual venv creation needed!** `uv sync` automatically:
  - Creates `.venv` if it doesn't exist
  - Installs all dependencies from `pyproject.toml`
  - Uses `uv.lock` for reproducible builds
</Note>

```bash
## uv sync creates .venv automatically and installs all dependencies
uv sync

## Verify installation
uv run python -c "import langgraph, anthropic; print('All imports successful')"
```

**Using Make (recommended):**

```bash
## Install all dependencies
make install-dev

## This runs:
## - uv sync
```

**Manual Virtual Environment (Optional):**

If you need manual control (e.g., specific Python version or custom location):

```bash
## Create venv manually with specific Python version
uv venv --python 3.12

## Activate it (only if needed)
## Linux/Mac:
source .venv/bin/activate

## Windows (PowerShell):
.venv\Scripts\Activate.ps1

## Windows (CMD):
.venv\Scripts\activate.bat

## Then install
uv sync
```

<Tip>
  Most developers don't need manual venv creation. Use `uv run <command>` to run commands in the virtual environment without activating it.
</Tip>

##### 4. Get LLM API Key

You need at least one LLM provider API key. Choose the one that works best for you:

**Option 1: Google Gemini (Recommended for Development)**

- FREE tier with generous limits
- Go to: https://aistudio.google.com/apikey
- Click "Get API key" â†’ "Create API key"
- Copy your key

**Option 2: Anthropic Claude**

- Requires payment
- Go to: https://console.anthropic.com/
- Settings â†’ API Keys â†’ Create Key
- Copy your key

**Option 3: OpenAI GPT**

- Requires payment
- Go to: https://platform.openai.com/api-keys
- Create new secret key
- Copy your key

**Option 4: Local Models (Ollama)**

```bash
## Install Ollama
curl -fsSL https://ollama.com/install.sh | sh

## Pull a model
ollama pull llama3.1

## No API key needed, runs locally!
```

##### 5. Configure Environment

```bash
## Copy example environment
cp .env.example .env

## Edit with your preferred editor
vim .env
## or
nano .env
## or
code .env  # VS Code
```

**Minimal .env configuration:**

```bash
## Choose your LLM provider
LLM_PROVIDER=google  # or anthropic, openai, ollama

## Add corresponding API key
GOOGLE_API_KEY=your-key-here
## or
ANTHROPIC_API_KEY=your-key-here
## or
OPENAI_API_KEY=your-key-here

## For Ollama (local), no key needed
LLM_PROVIDER=ollama
MODEL_NAME=llama3.1

## JWT secret (for development)
JWT_SECRET_KEY=dev-secret-change-in-production
```

##### 6. Start Infrastructure Services

```bash
## Start all services (OpenFGA, Jaeger, Prometheus, Grafana)
docker compose up -d

## Verify services are running
docker compose ps

## Should see:
## - openfga (port 8080)
## - postgres (port 5432)
## - jaeger (port 16686)
## - prometheus (port 9090)
## - grafana (port 3000)
```

**Check service health:**

```bash
## OpenFGA
curl http://localhost:8080/healthz

## Jaeger UI
open http://localhost:16686

## Prometheus
open http://localhost:9090

## Grafana (admin/admin)
open http://localhost:3000
```

##### 7. Setup OpenFGA Authorization

```bash
## Run setup script
uv run python scripts/setup_openfga.py

## This will output:
## âœ“ Created OpenFGA store: 01HXXXXXXXXX
## âœ“ Created authorization model: 01HYYYYYYYY
## âœ“ Wrote test tuples

## Copy the Store ID and Model ID to your .env
echo "OPENFGA_STORE_ID=01HXXXXXXXXX" >> .env
echo "OPENFGA_MODEL_ID=01HYYYYYYYY" >> .env
```

##### 8. Verify Installation

```bash
## Run unit tests
uv run pytest -m unit -v

## Should see all tests passing
## ===== X passed in Y.YYs =====

## Test the MCP server
uv run python examples/client_stdio.py

## Should see agent responses
```

---

### Development Workflow

#### Daily Development Cycle

```bash
## 1. Start your day - update from upstream
git fetch upstream
git checkout main
git merge upstream/main

## 2. Create feature branch
git checkout -b feat/your-feature

## 3. Start infrastructure
docker compose up -d

## 4. Make your changes
## ... edit code ...

## 5. Run tests frequently
uv run pytest -m unit -v

## 6. Format and lint before committing
make format
make lint

## 7. Commit your changes
git add .
git commit -m "feat: add new feature"

## 8. Push to your fork
git push origin feat/your-feature

## 9. Create Pull Request on GitHub
```

#### Using Make Commands

```bash
## See all available commands
make help

## Common commands:
make install-dev       # Install dependencies
make test              # Run all tests
make test-unit         # Run unit tests only
make test-coverage     # Run with coverage report
make format            # Format code with black/isort
make lint              # Run linters
make security-check    # Run security scans
make setup-infra       # Start Docker services
make clean             # Clean up generated files
```

#### IDE Setup

##### VS Code

Create `.vscode/settings.json`:

```json
{
  "python.defaultInterpreterPath": "${workspaceFolder}/.venv/bin/python",
  "python.linting.enabled": true,
  "python.linting.flake8Enabled": true,
  "python.linting.mypyEnabled": true,
  "python.formatting.provider": "black",
  "python.formatting.blackArgs": ["--line-length", "127"],
  "editor.formatOnSave": true,
  "python.testing.pytestEnabled": true,
  "python.testing.unittestEnabled": false,
  "[python]": {
    "editor.codeActionsOnSave": {
      "source.organizeImports": true
    }
  }
}
```

##### PyCharm

1. File â†’ Settings â†’ Project â†’ Python Interpreter
2. Add Interpreter â†’ Virtualenv Environment â†’ Existing
3. Select `.venv/bin/python`
4. Enable pytest: Settings â†’ Tools â†’ Python Integrated Tools â†’ Default test runner â†’ pytest

---

### Testing

#### Running Tests

```bash
## All tests
pytest

## Unit tests only (fast)
pytest -m unit -v

## Integration tests (requires services)
pytest -m integration -v

## Specific test file
pytest tests/test_auth.py -v

## Specific test function
pytest tests/test_auth.py::test_create_token -v

## With coverage
pytest --cov=. --cov-report=html

## Open coverage report
open htmlcov/index.html
```

#### Writing Tests

Create test files in `tests/` directory:

```python
## tests/test_my_feature.py
import pytest
from my_module import my_function

@pytest.mark.unit
def test_my_function():
    """Test my function does what it should"""
    result = my_function("input")
    assert result == "expected"

@pytest.mark.integration
async def test_my_integration():
    """Test integration with real service"""
    # Test with actual dependencies
    pass
```

#### Test Markers

- `@pytest.mark.unit` - Unit tests (no external deps)
- `@pytest.mark.integration` - Integration tests
- `@pytest.mark.e2e` - End-to-end tests
- `@pytest.mark.slow` - Slow tests (&gt;1 second)

---

### Debugging

#### Debug MCP Server

```bash
## Run with debug logging
LOG_LEVEL=DEBUG python -m mcp_server_langgraph.mcp.server_stdio

## Or set in .env
echo "LOG_LEVEL=DEBUG" >> .env
```

#### Debug with Python Debugger

```python
## Add breakpoint in code
import pdb; pdb.set_trace()

## Or use built-in (Python 3.7+)
breakpoint()
```

#### Debug Tests

```bash
## Run pytest with debugger
pytest --pdb

## Stop at first failure
pytest -x --pdb
```

#### View Traces

```bash
## Open Jaeger UI
open http://localhost:16686

## Select service: mcp-server-langgraph
## View traces with full context
```

#### Check Logs

```bash
## Docker service logs
docker compose logs -f

## Specific service
docker compose logs -f openfga

## Application logs (if LOG_FILE set)
tail -f mcp-server-langgraph.log
```

---

### Troubleshooting

#### Common Issues

##### "ModuleNotFoundError"

```bash
## Check if .venv exists
ls -la .venv

## Reinstall dependencies (creates .venv if needed)
uv sync

## Or use uv run to avoid activation issues
uv run python your_script.py
```

##### "Port already in use"

```bash
## Check what's using the port
lsof -i :8080  # Mac/Linux
netstat -ano | findstr :8080  # Windows

## Stop Docker services
docker compose down

## Restart
docker compose up -d
```

##### "OpenFGA connection refused"

```bash
## Check if OpenFGA is running
docker compose ps

## Check logs
docker compose logs openfga

## Restart service
docker compose restart openfga
```

##### "API key invalid"

```bash
## Verify key is set
echo $GOOGLE_API_KEY  # Linux/Mac
echo %GOOGLE_API_KEY%  # Windows

## Check .env file
cat .env | grep API_KEY

## Regenerate key from provider dashboard
```

##### Tests failing

```bash
## Update dependencies
uv sync

## Clear pytest cache
pytest --cache-clear

## Run specific failing test
pytest tests/test_name.py::test_function -v
```

#### Getting Help

1. **Check Documentation**
   - [Project README](https://github.com/vishnu2kmohan/mcp-server-langgraph/blob/main/README.md)
   - [Testing Guide](https://github.com/vishnu2kmohan/mcp-server-langgraph/blob/main/tests/README.md)

2. **Search Issues**
   - [Existing Issues](https://github.com/vishnu2kmohan/mcp-server-langgraph/issues)
   - [Closed Issues](https://github.com/vishnu2kmohan/mcp-server-langgraph/issues?q=is%3Aissue+is%3Aclosed)

3. **Ask Community**
   - [GitHub Discussions](https://github.com/vishnu2kmohan/mcp-server-langgraph/discussions)
   - Create new discussion with "Q&A" category

4. **Create Issue**
   - Use issue templates
   - Provide full context and logs

---

### Next Steps

- Read [CONTRIBUTING.md](https://github.com/vishnu2kmohan/mcp-server-langgraph/blob/main/CODE_OF_CONDUCT.md) for contribution guidelines
- Check [Good First Issues](https://github.com/vishnu2kmohan/mcp-server-langgraph/labels/good%20first%20issue)
- Join [GitHub Discussions](https://github.com/vishnu2kmohan/mcp-server-langgraph/discussions)
- Review [Code Style Guide](https://github.com/vishnu2kmohan/mcp-server-langgraph/blob/main/CODE_OF_CONDUCT.md#code-style)

**Happy Coding!** ðŸŽ‰
