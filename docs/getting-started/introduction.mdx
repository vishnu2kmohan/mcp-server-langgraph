---
title: Introduction
description: 'Welcome to MCP Server with LangGraph - A production-ready MCP server with enterprise features'
icon: 'rocket'
---

## What is MCP Server with LangGraph?

MCP Server with LangGraph is a **production-ready** MCP server implementation that combines the power of [LangGraph](https://langchain-ai.github.io/langgraph/) with the [Model Context Protocol (MCP)](https://modelcontextprotocol.io/), enhanced with enterprise-grade security, observability, and multi-cloud deployment capabilities.

<CardGroup cols={2}>
  <Card
    title="Quick Start"
    icon="rocket"
    href="/getting-started/quickstart"
  >
    Get up and running in 5 minutes
  </Card>
  <Card
    title="API Reference"
    icon="code"
    href="/api-reference/introduction"
  >
    Explore the API endpoints
  </Card>
  <Card
    title="Deploy to LangGraph Platform"
    icon="cloud"
    href="/deployment/langgraph-platform"
  >
    One-command serverless deployment
  </Card>
  <Card
    title="View on GitHub"
    icon="github"
    href="https://github.com/vishnu2kmohan/mcp-server-langgraph"
  >
    Star us on GitHub
  </Card>
</CardGroup>

## Key Features

<AccordionGroup>
  <Accordion icon="brain" title="Multi-LLM Support">
    Support for 100+ LLM providers via [LiteLLM](https://docs.litellm.ai/):
    - **Anthropic Claude** (3.5 Sonnet, 3 Opus)
    - **OpenAI GPT** (GPT-4, GPT-4 Turbo)
    - **Google Gemini** (2.5 Flash, 2.5 Pro)
    - **Azure OpenAI**
    - **AWS Bedrock**
    - **Local Models** via Ollama (Llama 3.1, Qwen 2.5, Mistral)

    Automatic fallback and retry logic ensures high availability.
  </Accordion>

  <Accordion icon="shield" title="Enterprise Security">
    Production-grade security features:
    - **JWT Authentication** - Secure token-based auth
    - **OpenFGA Authorization** - Fine-grained relationship-based access control (Zanzibar model)
    - **Infisical Integration** - Centralized secrets management
    - **Audit Logging** - Complete security event tracking
    - **Network Policies** - Kubernetes-native network isolation
  </Accordion>

  <Accordion icon="chart-line" title="Dual Observability">
    Complete visibility with dual observability stack:
    - **LangSmith** - LLM-specific tracing, prompt engineering, evaluations, cost tracking
    - **OpenTelemetry** - Distributed tracing with Jaeger, infrastructure metrics
    - **Prometheus** - Metrics collection and alerting
    - **Grafana Dashboards** - Pre-built visualizations
    - **Structured Logging** - JSON logs with trace correlation
  </Accordion>

  <Accordion icon="cloud" title="Multi-Cloud Deployment">
    Deploy anywhere with confidence:
    - **LangGraph Platform** - One-command serverless deployment (2 minutes)
    - **Google Cloud Run** - Serverless GCP with auto-scaling (10 minutes)
    - **Kubernetes** - Production-grade K8s on GKE, EKS, AKS (1-2 hours)
    - **Helm Charts** - Flexible, customizable K8s deployments
    - **Docker** - Quick Docker Compose setup for dev/test (15 minutes)
    - **GitOps Ready** - ArgoCD, FluxCD compatible
  </Accordion>
</AccordionGroup>

## Architecture

<Note>
For detailed system architecture diagrams including authentication flows, deployment options, and component interactions, see [System Architecture](/diagrams/system-architecture).
</Note>

The MCP Server follows a layered architecture:
- **Client Layer**: MCP protocol communication
- **Security Layer**: JWT authentication and OpenFGA authorization
- **Agent Layer**: LangGraph-powered agentic workflows
- **Provider Layer**: Multi-LLM support with automatic fallback
- **Observability Layer**: Dual monitoring with OpenTelemetry and LangSmith

## Use Cases

<CardGroup cols={3}>
  <Card title="AI Assistants" icon="robot">
    Build intelligent assistants with multi-turn conversations and context awareness
  </Card>
  <Card title="Automation Agents" icon="wand-magic-sparkles">
    Create autonomous agents that execute complex workflows
  </Card>
  <Card title="Enterprise AI" icon="building">
    Deploy secure, compliant AI systems for enterprise use
  </Card>
  <Card title="Research Platforms" icon="flask">
    Build research tools with multiple model support
  </Card>
  <Card title="Customer Support" icon="headset">
    Intelligent support bots with fine-grained permissions
  </Card>
  <Card title="DevOps Automation" icon="gears">
    AI-powered infrastructure management and monitoring
  </Card>
</CardGroup>

## Why Choose MCP Server with LangGraph?

<Note>
  Most AI agent frameworks are proof-of-concepts or tightly coupled to specific cloud providers. MCP Server with LangGraph is **production-ready** from day one with true multi-cloud flexibility.
</Note>

### Production-Ready vs Prototype Frameworks

| Feature | Prototype Frameworks | MCP Server with LangGraph |
|---------|---------------|---------------------|
| **Authentication** | ❌ None | ✅ JWT + OpenFGA (Zanzibar model) |
| **Multi-LLM** | ⚠️ Single provider | ✅ 100+ providers with fallback |
| **Observability** | ❌ Basic logs | ✅ Dual stack (LangSmith + OTEL) |
| **Secrets** | ⚠️ .env files | ✅ Infisical integration |
| **Kubernetes** | ❌ None | ✅ Production manifests (GKE/EKS/AKS) |
| **Security** | ⚠️ Basic | ✅ Enterprise-grade |
| **Documentation** | ⚠️ README only | ✅ Complete guides + time estimates |
| **Testing** | ❌ Minimal | ✅ **100% pass rate** (437/437) |
| **Multi-Cloud** | ⚠️ Single cloud | ✅ GCP, AWS, Azure, Platform |
| **Time to Production** | ⚠️ Weeks-Months | ✅ Hours-Days |

### Framework Comparison Landscape

The agent framework ecosystem has matured significantly in 2025. Here's how MCP Server with LangGraph compares to leading alternatives:

<AccordionGroup>
  <Accordion icon="code" title="vs Google ADK (Agent Development Kit)">
    **Google ADK** offers excellent Google Cloud integration and multi-agent hierarchies, but is tightly coupled to the Google ecosystem.

    **Choose Google ADK if:**
    - Deep Google Cloud/Vertex AI integration required
    - Gemini models are your primary focus
    - Agent-to-Agent (A2A) protocol needed

    **Choose MCP Server with LangGraph if:**
    - Multi-cloud flexibility is critical
    - You need provider-agnostic architecture
    - Enterprise security/compliance is mandatory
    - Complete documentation with deployment time estimates

    [Detailed Comparison →](/comparisons/vs-google-adk)
  </Accordion>

  <Accordion icon="wand-magic-sparkles" title="vs OpenAI AgentKit">
    **OpenAI AgentKit** provides a visual workflow builder and low-code experience, but is limited to OpenAI models with usage-based pricing.

    **Choose OpenAI AgentKit if:**
    - Non-technical users building agents
    - Visual workflow design preferred
    - OpenAI ecosystem commitment

    **Choose MCP Server with LangGraph if:**
    - Code-first approach preferred
    - Multi-LLM support essential (100+ providers)
    - Cost control needed (avoid vendor lock-in)
    - Self-hosted deployment required

    [Detailed Comparison →](/comparisons/vs-openai-agentkit)
  </Accordion>

  <Accordion icon="robot" title="vs Claude Agent SDK">
    **Claude Agent SDK** offers excellent Claude integration with automatic context management, but is limited to Anthropic models.

    **Choose Claude Agent SDK if:**
    - Claude models exclusively
    - Code-heavy agent tasks
    - Anthropic ecosystem preference

    **Choose MCP Server with LangGraph if:**
    - Multi-provider flexibility needed
    - Kubernetes/multi-cloud deployment
    - Enterprise authentication (Keycloak, SSO)
    - Production observability required

    [Detailed Comparison →](/comparisons/vs-claude-agent-sdk)
  </Accordion>

  <Accordion icon="diagram-project" title="vs LangGraph Cloud Platform">
    **LangGraph Cloud** offers 2-minute serverless deployment, but is a managed service with ongoing costs.

    **Choose LangGraph Cloud if:**
    - Serverless deployment only
    - Managed service preferred
    - Quick prototyping priority

    **Choose MCP Server with LangGraph if:**
    - Self-hosted deployment needed
    - Multi-cloud deployment flexibility (GCP, AWS, Azure)
    - Enterprise security requirements (OpenFGA, Keycloak)
    - Cost optimization through self-hosting
    - Complete control over infrastructure

    **Note:** MCP Server with LangGraph **also supports** LangGraph Cloud for serverless deployment (2-minute setup), giving you the best of both worlds.

    [Detailed Comparison →](/comparisons/vs-langgraph-cloud)
  </Accordion>

  <Accordion icon="users" title="vs CrewAI">
    **CrewAI** excels at role-based multi-agent teams with excellent documentation, but requires significant setup and scaling effort.

    **Choose CrewAI if:**
    - Role-based agent teamwork fits your use case
    - Quick prototyping (excellent getting-started experience)
    - Learning/experimentation phase

    **Choose MCP Server with LangGraph if:**
    - Production deployment is priority
    - Enterprise security/compliance required
    - Multi-cloud infrastructure needed
    - Complete observability stack essential
    - Kubernetes-native deployment

    [Detailed Comparison →](/comparisons/vs-crewai)
  </Accordion>

  <Accordion icon="microsoft" title="vs Microsoft AutoGen / Agent Framework">
    **Microsoft Agent Framework** (formerly AutoGen + Semantic Kernel) offers dynamic multi-agent collaboration, but is in transition with framework consolidation.

    **Choose Microsoft Agent Framework if:**
    - Azure ecosystem integration
    - .NET/C# development
    - Dynamic conversational agents

    **Choose MCP Server with LangGraph if:**
    - Python-first development
    - Multi-cloud flexibility (not Azure-only)
    - Stable, production-ready framework
    - Complete deployment documentation

    [Detailed Comparison →](/comparisons/vs-microsoft-autogen)
  </Accordion>
</AccordionGroup>

### When to Choose MCP Server with LangGraph

Choose MCP Server with LangGraph when you need:

✅ **Production-grade security** - JWT authentication, OpenFGA authorization (Zanzibar model), audit logging
✅ **Enterprise compliance** - GDPR, SOC 2, HIPAA readiness with complete audit trails
✅ **Multi-cloud flexibility** - Deploy to GCP, AWS, Azure, or LangGraph Platform without changes
✅ **Provider independence** - 100+ LLM providers with automatic fallback/retry
✅ **Complete observability** - Dual stack (LangSmith + OpenTelemetry) with pre-built dashboards
✅ **Time-to-production clarity** - Deployment time estimates (2 min to 2 hours depending on target)
✅ **Kubernetes-native** - Production manifests, Helm charts, GitOps ready
✅ **Battle-tested reliability** - 100% test pass rate (437/437 tests)

<Info>
  **Need help choosing?** See our [Framework Decision Guide](/comparisons/choosing-framework) for a detailed decision matrix based on your use case, team size, and requirements.
</Info>

## Community & Support

<CardGroup cols={2}>
  <Card title="GitHub Discussions" icon="comments" href="https://github.com/vishnu2kmohan/mcp-server-langgraph/discussions">
    Ask questions and share ideas
  </Card>
  <Card title="Issue Tracker" icon="bug" href="https://github.com/vishnu2kmohan/mcp-server-langgraph/issues">
    Report bugs and request features
  </Card>
  <Card title="Contributing" icon="code-pull-request" href="/advanced/contributing">
    Help improve the project
  </Card>
  <Card title="Security" icon="shield-halved" href="/security/overview">
    Report security vulnerabilities
  </Card>
</CardGroup>

## Next Steps

<Steps>
  <Step title="Install">
    Follow the [Quick Start](/getting-started/quickstart) guide to install and configure
  </Step>
  <Step title="Configure">
    Set up your [LLM provider](/guides/multi-llm-setup) and [authentication](/getting-started/authentication)
  </Step>
  <Step title="Deploy">
    Deploy to [Docker](/deployment/docker) or [Kubernetes](/deployment/kubernetes)
  </Step>
  <Step title="Monitor">
    Set up [observability](/deployment/monitoring) and monitoring
  </Step>
</Steps>

---

<Info>
  **Ready to get started?** Jump to the [Quick Start guide](/getting-started/quickstart) to have your agent running in 5 minutes!
</Info>
