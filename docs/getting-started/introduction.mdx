---
title: Introduction
description: 'Welcome to MCP Server with LangGraph - A production-ready MCP server with enterprise features'
icon: 'rocket'
---

## What is MCP Server with LangGraph?

MCP Server with LangGraph is a **production-ready** MCP server implementation that combines the power of [LangGraph](https://langchain-ai.github.io/langgraph/) with the [Model Context Protocol (MCP)](https://modelcontextprotocol.io/), enhanced with enterprise-grade security, observability, and multi-cloud deployment capabilities.

<CardGroup cols={2}>
  <Card
    title="Quick Start"
    icon="rocket"
    href="/getting-started/quickstart"
  >
    Get up and running in 5 minutes
  </Card>
  <Card
    title="API Reference"
    icon="code"
    href="/api-reference/introduction"
  >
    Explore the API endpoints
  </Card>
  <Card
    title="Deploy to LangGraph Platform"
    icon="cloud"
    href="/deployment/langgraph-platform"
  >
    One-command serverless deployment
  </Card>
  <Card
    title="View on GitHub"
    icon="github"
    href="https://github.com/vishnu2kmohan/mcp-server-langgraph"
  >
    Star us on GitHub
  </Card>
</CardGroup>

## Key Features

<AccordionGroup>
  <Accordion icon="brain" title="Multi-LLM Support">
    Support for 100+ LLM providers via [LiteLLM](https://docs.litellm.ai/):
    - **Anthropic Claude** (3.5 Sonnet, 3 Opus)
    - **OpenAI GPT** (GPT-4, GPT-4 Turbo)
    - **Google Gemini** (2.5 Flash, 2.5 Pro)
    - **Azure OpenAI**
    - **AWS Bedrock**
    - **Local Models** via Ollama (Llama 3.1, Qwen 2.5, Mistral)

    Automatic fallback and retry logic ensures high availability.
  </Accordion>

  <Accordion icon="shield" title="Enterprise Security">
    Production-grade security features:
    - **JWT Authentication** - Secure token-based auth
    - **OpenFGA Authorization** - Fine-grained relationship-based access control (Zanzibar model)
    - **Infisical Integration** - Centralized secrets management
    - **Audit Logging** - Complete security event tracking
    - **Network Policies** - Kubernetes-native network isolation
  </Accordion>

  <Accordion icon="chart-line" title="Dual Observability">
    Complete visibility with dual observability stack:
    - **LangSmith** - LLM-specific tracing, prompt engineering, evaluations, cost tracking
    - **OpenTelemetry** - Distributed tracing with Jaeger, infrastructure metrics
    - **Prometheus** - Metrics collection and alerting
    - **Grafana Dashboards** - Pre-built visualizations
    - **Structured Logging** - JSON logs with trace correlation
  </Accordion>

  <Accordion icon="cloud" title="Multi-Cloud Deployment">
    Deploy anywhere with confidence:
    - **LangGraph Platform** - One-command serverless deployment (2 minutes)
    - **Google Cloud Run** - Serverless GCP with auto-scaling (10 minutes)
    - **Kubernetes** - Production-grade K8s on GKE, EKS, AKS (1-2 hours)
    - **Helm Charts** - Flexible, customizable K8s deployments
    - **Docker** - Quick Docker Compose setup for dev/test (15 minutes)
    - **GitOps Ready** - ArgoCD, FluxCD compatible
  </Accordion>
</AccordionGroup>

## Architecture

<Note>
For detailed system architecture diagrams including authentication flows, deployment options, and component interactions, see [System Architecture](/diagrams/system-architecture).
</Note>

The MCP Server follows a layered architecture:
- **Client Layer**: MCP protocol communication
- **Security Layer**: JWT authentication and OpenFGA authorization
- **Agent Layer**: LangGraph-powered agentic workflows
- **Provider Layer**: Multi-LLM support with automatic fallback
- **Observability Layer**: Dual monitoring with OpenTelemetry and LangSmith

## Use Cases

<CardGroup cols={3}>
  <Card title="AI Assistants" icon="robot">
    Build intelligent assistants with multi-turn conversations and context awareness
  </Card>
  <Card title="Automation Agents" icon="wand-magic-sparkles">
    Create autonomous agents that execute complex workflows
  </Card>
  <Card title="Enterprise AI" icon="building">
    Deploy secure, compliant AI systems for enterprise use
  </Card>
  <Card title="Research Platforms" icon="flask">
    Build research tools with multiple model support
  </Card>
  <Card title="Customer Support" icon="headset">
    Intelligent support bots with fine-grained permissions
  </Card>
  <Card title="DevOps Automation" icon="gears">
    AI-powered infrastructure management and monitoring
  </Card>
</CardGroup>

## Why Choose MCP Server with LangGraph?

<Note>
  MCP Server with LangGraph is **production-ready** from day one with enterprise-grade security, complete observability, and true multi-cloud flexibility. See our detailed comparisons with specific frameworks below.
</Note>

<Tip>
  **Choosing the right framework?** We've created a comprehensive [Framework Decision Guide](/comparisons/choosing-framework) with decision trees, comparison matrices by use case, team type analysis, and real-world scenarios to help you make the best choice for your project.
</Tip>

### Framework Comparison Landscape

The agent framework ecosystem has matured significantly in 2025. Here's how we compare to leading alternatives:

<CardGroup cols={3}>
  <Card
    title="vs Google ADK"
    icon="code"
    href="/comparisons/vs-google-adk"
  >
    Excellent Google Cloud integration but tightly coupled to GCP ecosystem
  </Card>
  <Card
    title="vs OpenAI AgentKit"
    icon="wand-magic-sparkles"
    href="/comparisons/vs-openai-agentkit"
  >
    Visual workflow builder limited to OpenAI models with usage-based pricing
  </Card>
  <Card
    title="vs Claude Agent SDK"
    icon="robot"
    href="/comparisons/vs-claude-agent-sdk"
  >
    Deep Claude integration with automatic context management, Anthropic-exclusive
  </Card>
  <Card
    title="vs LangGraph Cloud"
    icon="diagram-project"
    href="/comparisons/vs-langgraph-cloud"
  >
    2-minute serverless deployment as managed service with ongoing costs
  </Card>
  <Card
    title="vs CrewAI"
    icon="users"
    href="/comparisons/vs-crewai"
  >
    Role-based multi-agent teams, excellent for prototyping and learning
  </Card>
  <Card
    title="vs Microsoft Agent Framework"
    icon="microsoft"
    href="/comparisons/vs-microsoft-agent-framework"
  >
    Azure-integrated multi-agent collaboration with .NET/C# support
  </Card>
</CardGroup>

### When to Choose MCP Server with LangGraph

<CardGroup cols={2}>
  <Card title="Production Security & Compliance" icon="shield-halved">
    **Enterprise-grade security** with JWT authentication, OpenFGA authorization (Zanzibar model), and complete audit logging.

    **GDPR, SOC 2, HIPAA readiness** with audit trails for compliance requirements.
  </Card>
  <Card title="Multi-Cloud Flexibility" icon="cloud">
    **Deploy anywhere** - GCP, AWS, Azure, or LangGraph Platform without code changes.

    **Kubernetes-native** with production manifests, Helm charts, and GitOps ready infrastructure.
  </Card>
  <Card title="Complete Observability" icon="chart-line">
    **Dual monitoring stack** - LangSmith for LLM-specific insights + OpenTelemetry for infrastructure metrics.

    **Time-to-production clarity** with deployment estimates (2 min to 2 hours) for every target platform.
  </Card>
  <Card title="Provider Independence & Reliability" icon="circle-check">
    **100+ LLM providers** with automatic fallback and retry logic for high availability.

    **Battle-tested** with 100% test pass rate (437/437 tests) ensuring production reliability.
  </Card>
</CardGroup>

<Info>
  **Need help choosing?** See our [Framework Decision Guide](/comparisons/choosing-framework) for a detailed decision matrix based on your use case, team size, and requirements.
</Info>

## Community & Support

<CardGroup cols={2}>
  <Card title="GitHub Discussions" icon="comments" href="https://github.com/vishnu2kmohan/mcp-server-langgraph/discussions">
    Ask questions and share ideas
  </Card>
  <Card title="Issue Tracker" icon="bug" href="https://github.com/vishnu2kmohan/mcp-server-langgraph/issues">
    Report bugs and request features
  </Card>
  <Card title="Contributing" icon="code-pull-request" href="/advanced/contributing">
    Help improve the project
  </Card>
  <Card title="Security" icon="shield-halved" href="/security/overview">
    Report security vulnerabilities
  </Card>
</CardGroup>

## Next Steps

<Steps>
  <Step title="Install">
    Follow the [Quick Start](/getting-started/quickstart) guide to install and configure
  </Step>
  <Step title="Configure">
    Set up your [LLM provider](/guides/multi-llm-setup) and [authentication](/getting-started/authentication)
  </Step>
  <Step title="Deploy">
    Deploy to [Docker](/deployment/docker) or [Kubernetes](/deployment/kubernetes)
  </Step>
  <Step title="Monitor">
    Set up [observability](/deployment/monitoring) and monitoring
  </Step>
</Steps>

---

<Info>
  **Ready to get started?** Jump to the [Quick Start guide](/getting-started/quickstart) to have your agent running in 5 minutes!
</Info>
