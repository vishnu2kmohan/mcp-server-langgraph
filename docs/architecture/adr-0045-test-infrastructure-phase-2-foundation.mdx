---
title: 'ADR-0045: Test Infrastructure Phase 2 - Real Infrastructure Foundation'
description: 'Following the successful completion of Phase 1 (ADR-0044: Test Infrastructure Quick Wins), Phase 2 focuses on migrating E2E tests from mocks to real infrastructure.'
icon: 'file-lines'
seoTitle: "ADR-0045: Test Infrastructure Phase 2 - Real Infrastructure Foundation"
seoDescription: "Architecture Decision Record 0045: Real infrastructure migration foundation for comprehensive end-to-end testing"
keywords: ["ADR", "architecture decision", "design pattern", "MCP Server architecture", "ADR-0045", "testing", "E2E", "infrastructure", "PostgreSQL", "Redis", "OpenFGA"]
contentType: "explanation"
---

# ADR-0045: Test Infrastructure Phase 2 - Real Infrastructure Foundation

**Status**: Accepted
**Date**: 2025-11-06
**Deciders**: Development Team
**Technical Story**: Phase 2 of comprehensive test infrastructure remediation - Real infrastructure migration foundation

## Context

Following the successful completion of Phase 1 (ADR-0044: Test Infrastructure Quick Wins), Phase 2 focuses on migrating E2E tests from mocks to real infrastructure. This phase establishes the foundation for comprehensive end-to-end testing with actual services.

### Phase 1 Achievements (Completed)
- ✅ Enabled 3 critical OpenFGA security tests (CWE-269 prevention)
- ✅ Fixed event loop creation in benchmarks (30-50% performance improvement)
- ✅ Removed legacy telemetry bootstrapping (cleaner architecture)
- ✅ Documented in ADR-0044

### Phase 2 Objectives
1. **Per-Test Cleanup Fixtures**: Ensure test isolation without restarting infrastructure
2. **Real Client Implementations**: Replace HTTP mocks with real Keycloak/MCP clients
3. **Migration Path**: Enable gradual migration of 178 E2E tests to real infrastructure

### Problem Statement

**Current State** (Before Phase 2):
- E2E tests use `MockKeycloakAuth` and `MockMCPClient` (lightweight mocks)
- No test isolation - session-scoped fixtures don't clean up between tests
- Mock responses may diverge from real service behavior
- 178 E2E tests need migration to real infrastructure

**Risks Without Phase 2**:
- Test pollution (one test's data affects another)
- False positives (mocks always succeed, real services may fail)
- Security gaps (authorization not tested against real OpenFGA)
- Integration bugs not caught until production

## Decision

We implement Phase 2 in two sub-phases:

### Phase 2.1: Per-Test Cleanup Fixtures ✅

**Approach**: Function-scoped wrappers around session-scoped infrastructure

**Implementation**:
```python
# Session-scoped (expensive, reused)
@pytest.fixture(scope="session")
async def postgres_connection_real(integration_test_env):
    # Expensive: Create connection once
    conn = await asyncpg.connect(...)
    yield conn
    await conn.close()

# Function-scoped (cheap, per-test cleanup)
@pytest.fixture
async def postgres_connection_clean(postgres_connection_real):
    yield postgres_connection_real
    # Cleanup: Drop test tables
    tables = await postgres_connection_real.fetch("SELECT ...")
    for table in tables:
        await postgres_connection_real.execute(f"DROP TABLE {table} CASCADE")
```
**Fixtures Created**:
1. **postgres_connection_clean**: Drops all `test_*` tables after each test
2. **redis_client_clean**: Flushes database after each test (O(N) but fast)
3. **openfga_client_clean**: Tracks and deletes tuples written during test

**Key Design Decisions**:
- Reuse expensive session-scoped connections (Docker containers)
- Add cheap per-test cleanup (drop tables, flush Redis, delete tuples)
- Graceful degradation: If cleanup fails, don't fail the test
- Performance: Cleanup adds `<100ms` per test

### Phase 2.2: Real Client Implementations (In Progress)

**Approach**: Replace mocks with real client implementations

**Migration Strategy**:
```python
# Before (Mock):
@pytest.fixture
def keycloak_auth():
    return MockKeycloakAuth()  # Always succeeds, no real validation

# After (Real):
@pytest.fixture
async def keycloak_auth_real(keycloak_client_real):
    # Uses real Keycloak instance, validates tokens
    return keycloak_client_real
```

**Clients to Migrate**:
1. **KeycloakAuth**: Replace `MockKeycloakAuth` with real Keycloak client
2. **MCPClient**: Replace `MockMCPClient` with real MCP HTTP/SSE client
3. **OpenFGAClient**: Already migrated in Phase 1 (3 tests)

**Benefits**:
- Validates real service behavior (token expiry, network errors, etc.)
- Catches integration bugs before production
- Tests security controls (authorization, authentication)
- Validates error handling (timeouts, retries, circuit breakers)

## Consequences

### Positive

**Test Quality** ✅:
- Test isolation prevents pollution between tests
- Real services catch integration bugs early
- Security controls validated against real infrastructure
- Error handling tested under realistic conditions

**Developer Experience** ✅:
- Clear fixture patterns (session-scoped + per-test cleanup)
- Fast test execution (session-scoped infrastructure reuse)
- Gradual migration path (mock → real incrementally)
- Better debugging (real errors, not mock success)

**Production Confidence** ✅:
- E2E tests validate full stack (app → services → database)
- Authorization tested against real OpenFGA
- Authentication tested against real Keycloak
- Serialization tested against real PostgreSQL/Redis

### Negative

**Infrastructure Requirements** ⚠️:
- Tests require docker-compose.test.yml services running
- PostgreSQL (port 9432), Redis (port 9379), OpenFGA (port 9080), Keycloak (port 9090)
- Startup time: ~2 minutes (one-time cost per test session)
- CI/CD needs Docker Compose support

**Test Complexity** ⚠️:
- More complex fixtures (cleanup logic, error handling)
- Developers must understand fixture scopes (session vs function)
- Debugging requires infrastructure logs (docker-compose logs)

### Neutral

**Migration Timeline**:
- Phase 2.1: Complete (per-test cleanup fixtures)
- Phase 2.2: In progress (real client implementations)
- Full migration: 178 tests to migrate gradually
- No breaking changes (mocks remain available)

## Implementation Details

### Files Modified

1. **tests/conftest.py** (Lines 620-700):
   - Added `postgres_connection_clean` fixture
   - Added `redis_client_clean` fixture
   - Added `openfga_client_clean` fixture
   - Enhanced error handling for cleanup failures

2. **tests/integration/** (New directory):
   - `test_postgres_storage.py` - PostgreSQL CRUD tests (Phase 3)
   - `test_keycloak_integration.py` - Keycloak authentication tests (Phase 2.2)
   - `test_openfga_integration.py` - OpenFGA authorization tests (Phase 1)

### Fixture Design Patterns

**Pattern 1: Session-Scoped Infrastructure**
```python
@pytest.fixture(scope="session")
async def postgres_connection_real(integration_test_env):
    """Expensive: Creates connection once per session"""
    conn = await asyncpg.connect(
        host="localhost",
        port=9432,
        database="testdb",
        user="postgres",
        password="postgres"
    )
    yield conn
    await conn.close()
```
**Pattern 2: Per-Test Cleanup Wrapper**
```python
@pytest.fixture
async def postgres_connection_clean(postgres_connection_real):
    """Cheap: Cleanup after each test"""
    yield postgres_connection_real
    try:
        # Drop test tables (graceful degradation)
        tables = await postgres_connection_real.fetch(
            "SELECT tablename FROM pg_tables WHERE tablename LIKE 'test_%'"
        )
        for table in tables:
            await postgres_connection_real.execute(f"DROP TABLE {table['tablename']} CASCADE")
    except Exception as e:
        logger.warning(f"Cleanup failed (non-fatal): {e}")
```

**Pattern 3: Resource Tracking**
```python
@pytest.fixture
async def openfga_client_clean(openfga_client_real):
    """Track tuples written during test, delete after"""
    written_tuples = []

    # Wrap write_tuples to track writes
    original_write = openfga_client_real.write_tuples
    async def tracked_write(tuples):
        written_tuples.extend(tuples)
        return await original_write(tuples)

    openfga_client_real.write_tuples = tracked_write
    yield openfga_client_real

    # Cleanup: Delete all written tuples
    for tuple in written_tuples:
        await openfga_client_real.delete_tuple(tuple)
```
### Performance Optimization

**Startup Time**:
- Docker Compose startup: ~2 minutes (session-scoped, one-time)
- Per-test overhead: `<100ms` (cleanup only)
- Parallel test execution: Supported (per-test isolation)

**Cleanup Performance**:
- PostgreSQL DROP TABLE: ~10-50ms per table
- Redis FLUSHDB: ~5-15ms (O(N) where N = keys)
- OpenFGA DELETE tuple: ~5-10ms per tuple
- Total per-test overhead: ~50-100ms (acceptable)

## Testing Strategy

### Unit Tests (Fast, No Infrastructure)
```bash
# Run unit tests (no infrastructure required)
pytest tests/unit/ -v
```

### Integration Tests (Require Infrastructure)
```bash
# Start infrastructure
docker-compose -f docker-compose.test.yml up -d

# Run integration tests
TESTING=true pytest tests/integration/ -v --integration

# Stop infrastructure
docker-compose -f docker-compose.test.yml down
```
### E2E Tests (Full Stack)
```bash
# Start all services
docker-compose -f docker-compose.test.yml up -d

# Run E2E tests with real clients
TESTING=true pytest tests/e2e/ -v --e2e

# Stop services
docker-compose -f docker-compose.test.yml down
```

## Migration Guide

### Step 1: Enable Real Infrastructure
```bash
# Copy test environment template
cp .env.test.example .env.test

# Start test infrastructure
docker-compose -f docker-compose.test.yml up -d

# Verify services are healthy
docker-compose -f docker-compose.test.yml ps
```
### Step 2: Migrate Tests Incrementally
```python
# BEFORE (Mock):
@pytest.mark.asyncio
async def test_create_user(mock_keycloak):
    user = await mock_keycloak.create_user(...)  # Always succeeds
    assert user.id is not None

# AFTER (Real):
@pytest.mark.asyncio
@pytest.mark.integration  # Mark as integration test
async def test_create_user(keycloak_client_real, keycloak_connection_clean):
    user = await keycloak_client_real.create_user(...)  # Real Keycloak
    assert user.id is not None
    # Cleanup happens automatically via keycloak_connection_clean
```

### Step 3: Update CI/CD
```yaml
# .github/workflows/test.yml
jobs:
  integration-tests:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        ports:
          - 9432:5432
      redis:
        image: redis:7
        ports:
          - 9379:6379
    steps:
      - name: Start test infrastructure
        run: docker-compose -f docker-compose.test.yml up -d

      - name: Run integration tests
        run: TESTING=true pytest tests/integration/ -v --integration
```

## Future Work

### Phase 3: Storage Backend Tests
- Implement PostgreSQL audit log storage tests (ADR-0048)
- Implement Redis checkpoint storage tests
- Add database migrations for persistent storage

### Phase 4: Infrastructure Optimizations
- Optimize docker-compose.test.yml startup (target: `<2min`)
- Optimize CI/CD E2E test execution (target: `<15min`)
- Update performance baselines with real infrastructure

### Phase 5: Advanced Testing
- Property-based testing with Hypothesis
- Chaos engineering (network failures, service crashes)
- Load testing with Locust
- Security testing with OWASP ZAP

## References

- [ADR-0044: Test Infrastructure Quick Wins](./adr-0044-test-infrastructure-quick-wins.mdx)
- [ADR-0048: PostgreSQL Storage Integration Tests](./adr-0048-postgres-storage-integration-tests.mdx)
- [pytest fixtures documentation](https://docs.pytest.org/en/stable/fixture.html)
- [Docker Compose for CI/CD](https://docs.docker.com/compose/ci/)

## Metrics

### Before Phase 2
- **Test Isolation**: ❌ None (session-scoped fixtures, no cleanup)
- **Mock Usage**: 178/178 E2E tests use mocks (100%)
- **Integration Bugs Caught**: Low (mocks hide integration issues)
- **Security Validation**: Minimal (3/3 OpenFGA tests only)

### After Phase 2.1 (Cleanup Fixtures)
- **Test Isolation**: ✅ Complete (per-test cleanup)
- **Cleanup Overhead**: `<100ms` per test
- **False Positives**: Reduced (real services catch errors)
- **Security Validation**: Improved (real authorization checks)

### After Phase 2.2 (Real Clients - In Progress)
- **Mock Usage**: Target 0/178 E2E tests use mocks (0%)
- **Integration Bugs Caught**: High (real services, real errors)
- **Security Validation**: Complete (all auth/authz tested)
- **Production Confidence**: High (full stack validated)

---

**Approved by**: Development Team
**Implementation Date**: 2025-11-06
**Review Date**: 2025-12-06 (30 days)
