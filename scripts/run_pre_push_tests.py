#!/usr/bin/env python3
"""
Pre-push test orchestrator - consolidates 5 separate pytest sessions into one.

This script addresses OpenAI Codex Finding 2a: Duplicate pytest sessions.

Problem:
  .pre-commit-config.yaml had 5 separate pytest invocations which caused:
  - 5x test discovery overhead (10-25s wasted)
  - 5 separate Python interpreter processes
  - Lock contention on .pytest_cache and .coverage files

  Each session performed full test discovery, causing:
  - 5x test discovery overhead (10-25s wasted)
  - 5 separate Python interpreter processes
  - Lock contention on .pytest_cache and .coverage files

Solution:
  Single pytest session with combined marker logic:
  - Discovers tests once (2-5s instead of 10-25s)
  - Single Python process with xdist workers
  - No cache/coverage lock contention
  - Same test coverage as before

Time savings: 8-20 seconds per pre-push

Environment variables:
  - OTEL_SDK_DISABLED=true (set by pre-commit hook)
  - CI_PARITY=1 (optional: run integration tests if Docker available)

Usage:
  # Via pre-commit hook (automatic)
  git push

  # Manual invocation
  python scripts/run_pre_push_tests.py

  # With integration tests (if Docker available)
  CI_PARITY=1 python scripts/run_pre_push_tests.py
"""

import os
import subprocess
import sys


def check_docker_available() -> bool:
    """Check if Docker daemon is available."""
    try:
        result = subprocess.run(
            ["docker", "info"],
            capture_output=True,
            timeout=5,
        )
        return result.returncode == 0
    except (FileNotFoundError, subprocess.TimeoutExpired):
        return False


def main() -> int:
    """
    Run consolidated pre-push test suite.

    Returns:
        0 if all tests pass, non-zero otherwise
    """
    # Build pytest arguments
    pytest_args = [
        "pytest",
        "-n",
        "auto",  # Parallel execution with pytest-xdist
        "-x",  # Stop on first failure (fail-fast)
        "--testmon",  # Optimize test execution with pytest-testmon
        "--tb=short",  # Short traceback format
    ]

    # Combined marker expression that covers all 5 original hooks:
    # 1. unit and not llm (run-unit-tests)
    # 2. smoke tests (run-smoke-tests)
    # 3. api and unit and not llm (run-api-tests)
    # 4. mcp-server tests (run-mcp-server-tests)
    # 5. property tests (run-property-tests)
    #
    # Strategy: Use marker OR logic to combine all test categories
    # Note: Smoke tests are unit tests in tests/smoke/, so covered by "unit"
    # Note: API tests are marked as "api and unit", so covered by "api"
    # Note: MCP server tests are in tests/unit/, marked as unit
    #
    # Codex Finding #5 Fix (2025-11-23): Exclude meta-tests from pre-push
    # Meta-tests validate infrastructure (git hooks, CI workflows, etc.)
    # They shell out to external processes and should run separately in CI
    #
    # Final expression: (unit or api or property) and not llm and not meta
    # This covers ALL tests from the 5 original hooks, excluding meta-tests
    marker_expression = "(unit or api or property) and not llm and not meta"
    pytest_args.extend(["-m", marker_expression])

    # Specify test directory
    pytest_args.append("tests/")

    # Check for CI_PARITY=1 to include integration tests
    ci_parity = os.getenv("CI_PARITY") == "1"
    if ci_parity:
        # User requested CI-equivalent validation
        if check_docker_available():
            print("â–¶ CI_PARITY=1 detected: Including integration tests (Docker available)")
            # Add integration marker to expression (but still exclude meta-tests)
            # (unit or api or property or integration) and not llm and not meta
            marker_expression = "(unit or api or property or integration) and not llm and not meta"
            pytest_args[pytest_args.index("(unit or api or property) and not llm and not meta")] = marker_expression
        else:
            print("âš  CI_PARITY=1 detected but Docker not available")
            print("  Integration tests require Docker daemon")
            print("  Start Docker and retry, or omit CI_PARITY=1 for faster pre-push")
            print("  Continuing with standard test suite...")

    # Ensure OTEL_SDK_DISABLED and HYPOTHESIS_PROFILE for consistent environment
    env = os.environ.copy()
    env["OTEL_SDK_DISABLED"] = "true"

    # Codex Finding #4 Fix (2025-11-23): Environment-aware Hypothesis profiles
    # Use dev profile (25 examples) locally for faster iteration
    # Use ci profile (100 examples) in CI or when explicitly requested
    if "HYPOTHESIS_PROFILE" not in env:
        # Auto-detect: Use CI profile in CI/CD or when CI_PARITY requested
        if env.get("CI") or env.get("CI_PARITY") == "1":
            env["HYPOTHESIS_PROFILE"] = "ci"
        else:
            env["HYPOTHESIS_PROFILE"] = "dev"  # Fast iteration for local dev

    hypothesis_profile = env["HYPOTHESIS_PROFILE"]
    examples_count = "100" if hypothesis_profile == "ci" else "25"

    # Run pytest via uv run (auto-syncs if needed)
    print(f"â–¶ Running consolidated pre-push tests: {' '.join(pytest_args)}")
    print(f"  Marker expression: {marker_expression}")
    print(f"  Hypothesis profile: {hypothesis_profile} ({examples_count} examples)")
    if hypothesis_profile == "dev":
        print("  ðŸ’¡ Tip: Use CI_PARITY=1 git push for full CI validation (100 examples)")
    print()

    result = subprocess.run(
        ["uv", "run"] + pytest_args,
        env=env,
    )

    if result.returncode == 0:
        print()
        print("âœ“ All pre-push tests passed")
        print("  Tests consolidated from 5 sessions â†’ 1 session (8-20s faster)")
    else:
        print()
        print("âœ— Pre-push tests failed")
        print("  Fix failing tests before pushing")

    return result.returncode


if __name__ == "__main__":
    sys.exit(main())
