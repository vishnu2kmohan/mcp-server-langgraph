repos:
- repo: https://github.com/pre-commit/pre-commit-hooks
  rev: v6.0.0
  hooks:
  - id: trailing-whitespace
  - id: end-of-file-fixer
  - id: check-yaml
    args:
    - --allow-multiple-documents
    exclude: ^deployments/helm/mcp-server-langgraph/templates/
  - id: check-added-large-files
    args:
    - --maxkb=500
    exclude: ^uv\.lock$
  - id: check-merge-conflict
  - id: detect-private-key
    # Exclude secrets obfuscation test file which intentionally contains fake/truncated test keys
    exclude: ^tests/unit/secrets_obfuscation/test_secrets_obfuscation\.py$
  - id: check-json
  - id: check-toml
  - id: mixed-line-ending
  - id: check-ast
    name: Check Python AST (Syntax Validation)
    description: 'Validates Python files can be parsed (no SyntaxError).

      Prevents commits of syntactically invalid Python code.

      Regression prevention for commit a57fcc95 (pytestmark inside imports).
      '
- repo: https://github.com/astral-sh/ruff-pre-commit
  rev: v0.14.6  # Latest stable (2025-11-21) - synced with pyproject.toml dev dependency
  hooks:
  - id: ruff
    name: Ruff Linter (replaces isort + flake8)
    args:
    - --fix
    exclude: ^clients/(python|go|typescript)/
  - id: ruff-format
    name: Ruff Formatter (replaces Black)
    args:
    - --line-length=127
    exclude: ^clients/(python|go|typescript)/
- repo: https://github.com/pycqa/bandit
  rev: 1.8.6
  hooks:
  - id: bandit
    args:
    - -lll
    - --skip
    - B608
    stages:
      - pre-push
- repo: https://github.com/pre-commit/mirrors-mypy
  rev: v1.13.0
  hooks:
  - id: mypy
    name: MyPy Type Checking (Blocking)
    # CRITICAL: Use --frozen to ensure lockfile-pinned versions (prevents version drift in CI)
    entry: uv run --frozen mypy src/mcp_server_langgraph
    language: system
    types: [python]
    args:
    - --config-file=pyproject.toml
    - --show-error-codes
    - --pretty
    pass_filenames: false
    # MyPy Configuration Status (2025-11-27)
    #
    # ✅ FIXED: All type errors resolved!
    # ✅ ENVIRONMENT: Uses uv-managed environment with --frozen flag
    # Stage: pre-push (BLOCKING - maintains local/CI parity)
    #
    # Modern best practice: Per-module overrides in pyproject.toml
    #   - Strict mode for internal code (ignore_missing_imports = false)
    #   - Lenient mode for third-party libraries (per-module overrides)
    #
    # Environment approach:
    #   - language: system (uses uv-managed environment)
    #   - --frozen ensures lockfile-pinned versions (prevents types-redis drift)
    #   - Matches local development and CI/CD exactly
    #
    # Test: tests/meta/test_mypy_enforcement.py::test_mypy_passes_on_current_codebase ✅
    stages:
    - pre-push
- repo: https://github.com/gitleaks/gitleaks
  rev: v8.28.0
  hooks:
  - id: gitleaks
- repo: local
  hooks:
  # NOTE: mypy-non-blocking hook REMOVED (2025-11-23)
  # Reason: Redundant now that main MyPy hook is enabled and blocking
  # Main MyPy hook runs on pre-push stage and fails on type errors
  # This maintains local/CI parity (no more non-blocking warnings)
  - id: check-subprocess-timeout
    name: Enforce subprocess timeout parameters
    description: 'Ensures all subprocess.run() calls include timeout parameter to prevent test hangs.


      Prevents regression of 119 subprocess.run() calls without timeout.

      Fix: Add timeout=60 parameter to subprocess.run() calls.

      '
    entry: uv run --frozen python -u .pre-commit-hooks/check_subprocess_timeout.py
    language: system
    types: [python]
    files: ^tests/.*\.py$
    stages:
    - pre-push
  - id: check-banned-imports
    name: Validate no banned/deprecated imports
    description: 'Detects usage of deprecated imports (e.g., toml instead of tomllib).


      Prevents issues like:
      - import toml (deprecated in Python 3.11+)
      - import imp (removed in Python 3.12+)

      '
    entry: uv run --frozen python -u .pre-commit-hooks/check_banned_imports.py
    language: system
    types: [python]
    stages:
    - pre-push
  - id: uv-lock-check
    name: Validate uv.lock synchronized with pyproject.toml
    entry: bash -c 'uv lock --check || (echo "ERROR - uv.lock out of sync. Run uv lock"; exit 1)'
    language: system
    files: ^(pyproject\.toml|uv\.lock)$
    pass_filenames: false
    stages:
    - pre-commit
    - pre-push
  - id: uv-pip-check
    name: Validate no dependency conflicts
    entry: bash -c 'uv pip check || (echo "ERROR - Dependency conflicts detected. Run uv pip check to see details"; exit 1)'
    language: system
    pass_filenames: false
    stages:
    - pre-commit
    - pre-push
    description: 'Validates that installed dependencies have no conflicts.


      Why this check is critical:
      - uv lock --check validates lockfile is current
      - uv pip check validates no dependency conflicts exist
      - Both are needed for comprehensive dependency validation

      Example failure this prevents:
      1. Package A requires foo>=2.0, Package B requires foo<2.0
      2. uv lock succeeds and generates lockfile (lock check passes)
      3. uv pip check FAILS (conflict detected)
      4. Without this hook: conflict pushed to CI and fails there

      Matches CI validation in .github/workflows/ci.yaml
      Test: tests/meta/test_local_ci_parity.py::test_pre_push_includes_uv_pip_check

      '
  - id: run-pre-push-tests
    name: Run Pre-Push Tests (consolidated - dev profile)
    # CRITICAL: OTEL_SDK_DISABLED must be set BEFORE uv run to prevent pytest-xdist
    # workers from initializing OpenTelemetry background threads that cause timeouts.
    # See: tests/meta/test_mypy_enforcement.py timeout fix (2025-12-01)
    entry: bash -c 'OTEL_SDK_DISABLED=true uv run --frozen python -u scripts/run_pre_push_tests.py'
    language: system
    pass_filenames: false
    files: ^(src/.*\.py|tests/.*\.py|pyproject\.toml|deployments/.*\.(yaml|yml)|docker/.*\.(yaml|yml)|\.github/.*\.ya?ml)$
    always_run: false
    stages:
    - pre-push
    description: 'Consolidated pre-push test suite (OpenAI Codex Finding 2a fix).


      Consolidates 21 separate pytest invocations into 1 for efficiency:

      - Combined marker: -m "(unit or api or property or validation) and not llm"

      - This covers: unit tests, smoke tests, API tests, property tests, deployment validation

      - Meta tests included conditionally when workflow files change


      Time savings: ~4 minutes (reduced test discovery from 21 sessions to 1)


      CI_PARITY mode: Set CI_PARITY=1 to include integration tests (requires Docker)

      Example: CI_PARITY=1 git push


      Benefits:

      - Single test discovery (~13s instead of ~4.5 min for 21 sessions)

      - No pytest cache/coverage lock contention

      - Fail-fast across all test categories

      - Parallel execution with pytest-xdist (-n auto)


      CI Parity: CI runs with HYPOTHESIS_PROFILE=ci (100 examples)

      Local Speed: 3-5min (vs 8-12min with CI profile)


      Full CI-equivalent validation: make validate-pre-push or CI_PARITY=1 git push

      '
  - id: python-version-smoke-test
    name: Multi-Python Version Smoke Test (quick)
    entry: scripts/test_python_versions.sh --quick
    language: script
    pass_filenames: false
    always_run: true
    stages:
    - pre-push
    description: 'Run quick smoke tests on available Python versions (3.11, 3.12, 3.13).

      Added 2025-11-28 in response to PR #121 CI failures where Python 3.11/3.13
      failed but 3.12 passed due to bleeding-edge dependency issues.

      Uses --quick mode for speed (~30s total). Tests current venv only.
      Docker build smoke test (separate hook) catches extra reference issues.

      This hook catches version-specific import problems before they reach CI:
      - Tests Click CLI functionality (catches _textwrap issues)
      - Tests Hypothesis property tests (catches internal module changes)

      To run full mode: ./scripts/test_python_versions.sh (without --quick)
      For CI mode (fail on missing versions): ./scripts/test_python_versions.sh --ci

      '
  - id: docker-build-smoke-test
    name: Docker Build Smoke Test
    entry: >
      bash -c 'docker build -f docker/Dockerfile --target build-test . -q >/dev/null 2>&1 ||
      (echo "ERROR - Docker build failed. Check docker/Dockerfile and pyproject.toml extras." && exit 1)'
    language: system
    pass_filenames: false
    always_run: true
    stages:
    - pre-push
    description: 'Validates Docker build succeeds before pushing to CI.

      Added 2025-11-28 to catch configuration mismatches between pyproject.toml
      and Docker files (e.g., removed extras still referenced in Dockerfiles).

      Builds the test stage only (fast, ~30s) to validate all --extra references
      exist in pyproject.toml and uv sync succeeds with the specified extras.

      Skips silently if Docker is not available.
      Duration: ~30s when Docker is available.

      '
  - id: run-integration-tests
    name: Run Integration Tests (manual - requires Docker)
    entry: bash -c 'PYTHONUNBUFFERED=1 OTEL_SDK_DISABLED=true uv run --frozen pytest -n auto tests/integration/ -v --tb=short'
    language: system
    pass_filenames: false
    files: ^(src/.*\.py|tests/integration/.*\.py)$
    always_run: false
    stages:
    - manual
    description: 'Runs integration tests with real infrastructure (Docker required).


      Moved to manual stage 2025-11-16 per OpenAI Codex finding - integration

      tests require Docker stack and add 2-3min to pre-push duration.


      Run manually: SKIP= pre-commit run run-integration-tests --all-files

      Or via make: make test-integration

      Or with pre-push: CI_PARITY=1 git push (auto-includes if Docker available)


      CI runs these automatically. Use for local validation of integration changes.

      '
- repo: https://github.com/python-jsonschema/check-jsonschema
  rev: 0.29.4
  hooks:
  - id: check-github-workflows
    name: Validate GitHub Actions workflows
    description: Validates GitHub Actions workflow syntax
    files: ^\.github/workflows/.*\.ya?ml$
- repo: local
  hooks:
  - id: actionlint-workflow-validation
    name: Validate GitHub Actions with actionlint
    entry: >
      bash -c 'if command -v actionlint >/dev/null 2>&1; then
      actionlint -no-color -shellcheck= .github/workflows/*.yml .github/workflows/*.yaml 2>&1;
      else echo "ERROR: actionlint not installed. Install from https://github.com/rhysd/actionlint";
      echo "  macOS: brew install actionlint";
      echo "  Linux: go install github.com/rhysd/actionlint/cmd/actionlint@latest";
      exit 1; fi'
    language: system
    files: ^\.github/workflows/.*\.ya?ml$
    pass_filenames: false
    always_run: false
    stages:
    - pre-push
    description: 'Advanced GitHub Actions workflow validation using actionlint.


      REQUIRED: actionlint must be installed. The hook will FAIL if not available.


      Install: brew install actionlint (macOS) or go install github.com/rhysd/actionlint/cmd/actionlint@latest


      Catches issues like:

      - Invalid context usage (secrets.* in job-level if conditions)

      - Missing job dependencies (needs declarations)

      - Expression syntax errors

      - Invalid workflow syntax


      Complements check-github-workflows with deeper validation.

      '
  - id: check-test-sleep-duration
    name: Check Test Sleep Durations
    entry: uv run --frozen python -u scripts/validators/check_test_sleep_duration.py
    language: system
    files: ^tests/.*\.py$
    exclude: ^tests/meta/test_sleep_duration_linter\.py$
    pass_filenames: true
    description: 'Prevents test performance regressions by detecting excessive sleep() calls.


      Enforces:

      - Unit tests: max 0.5s sleep

      - Integration tests: max 2.0s sleep


      Use VirtualClock for instant time advancement instead of real sleep.

      '
  - id: validate-fast
    name: Run Fast Validators (Consolidated)
    entry: uv run --frozen python -u scripts/validators/validate_fast.py
    language: system
    pass_filenames: false
    always_run: true
    stages:
    - pre-push
    description: "Consolidated runner for fast validation scripts to reduce overhead.\nIncludes: pytest-config, pre-push-hook, repo-root, time-bombs, async-fixture-scope, migration-idempotency, api-schemas."

  - id: validate-docs
    name: Validate Documentation (Consolidated - MDX, Naming, Icons, ADR, Tests)
    entry: uv run --frozen python -u scripts/validators/validate_docs.py --all
    language: system
    files: ^(docs/.*\.(md|mdx|json)|adr/.*\.md)$
    pass_filenames: false
    always_run: false
    stages:
    - pre-push
    description: |
      Consolidated documentation validator (CI parity fix - 2025-11-29).

      Replaces 7 separate hooks with 1 unified validator:
      - validate-mdx-extensions → --mdx flag
      - check-frontmatter-quotes → --mdx flag
      - validate-file-naming-conventions → --mdx flag
      - validate-frontmatter-icons → --icons flag (NEW)
      - validate-adr-sync → --adr flag
      - validate-documentation-integrity → --tests flag
      - validate-documentation-structure → --tests flag

      Validates:
      ✅ All docs/ files use .mdx extension (not .md)
      ✅ Filenames follow kebab-case convention
      ✅ Frontmatter uses consistent quote style
      ✅ Icons use single quotes and are in valid registry
      ✅ All ADR files have contextual icons
      ✅ ADRs synchronized between adr/ and docs/architecture/
      ✅ No uppercase ADR-* filenames
      ✅ Runs documentation validation pytest tests

      Benefits:
      - 40% faster pre-push (single file scan instead of 7)
      - Full CI parity (runs same validations as CI)
      - Single Python process instead of 7+

      Manual run:
      $ python scripts/validators/validate_docs.py --all
      $ python scripts/validators/validate_docs.py --mdx --docs-dir docs/
      $ python scripts/validators/validate_docs.py --adr --repo-root .

      Tests: tests/unit/validators/test_validate_docs.py
  - id: audit-todo-fixme-markers
    name: Audit TODO/FIXME/XXX Markers in Documentation
    entry: uv run --frozen python -u scripts/validators/todo_audit.py --quiet
    language: system
    files: ^docs/.*\.(md|mdx)$
    pass_filenames: false
    always_run: false
    stages:
    - manual
    description: "Audits documentation for TODO/FIXME/XXX markers (TDD):\n- Finds all TODO and FIXME comments\n- Detects XXX\
      \ placeholders in examples\n- Reports location and content\n- Tracks outstanding work items\n\nNote: This is informational\
      \ only (exit code 0). Use for audits.\nRun manually: python scripts/validators/todo_audit.py --docs-dir docs\nTests:\
      \ tests/unit/documentation/test_todo_audit.py (14 tests \u2705)\n"
  - id: mintlify-broken-links-check
    name: Mintlify Broken Links Validation (PRIMARY Validator)
    entry: >
      bash -c 'if ! command -v npm >/dev/null 2>&1; then
      echo "ERROR: npm/Node.js required for Mintlify validation.";
      echo "Install via mise: curl https://mise.run | sh && mise install";
      echo "Or install Node.js from https://nodejs.org/";
      exit 1; fi;
      REPO_ROOT=$(git rev-parse --show-toplevel) && cd "$REPO_ROOT/docs" &&
      OUTPUT=$(npm exec -- mintlify broken-links 2>&1) && echo "$OUTPUT" &&
      if echo "$OUTPUT" | grep -q "found.*broken"; then
        echo ""; echo "ERROR: Broken links detected. Fix them before pushing.";
        exit 1;
      fi'
    language: system
    # Pattern expanded (P1-1 - 2025-11-27): Now triggers on MDX, JSON (navigation), and images
    files: ^docs/.*\.(mdx|json|png|jpg|jpeg|gif|svg|webp)$
    pass_filenames: false
    always_run: false
    stages:
    - pre-push
    description: "\U0001F3AF PRIMARY VALIDATOR for Mintlify documentation (docs/)\n\nThis is now the AUTHORITATIVE validator\
      \ for docs/ - runs on pre-push and in CI.\nReplaces 5 previous Python validators (link_validator, navigation_validator,\n\
      image_validator, frontmatter_validator, check_internal_links).\n\nComprehensive Checks (2025-11-15 - Simplified Validation):\n\
      \u2705 All internal links resolve correctly\n\u2705 Anchor links are valid (#section references)\n\u2705 Navigation\
      \ references work (docs.json \u2194 MDX files)\n\u2705 Page cross-references are accurate\n\u2705 Image references are\
      \ valid\n\u2705 Frontmatter is complete (title, description)\n\u2705 MDX syntax is valid\n\u2705 No orphaned pages\n\
      \nRuns automatically on git push (pre-push stage):\n- Duration: ~8-12s (acceptable within pre-push 8-12 min budget)\n\
      - Catches MDX syntax errors BEFORE pushing to remote\n- Prevents broken documentation from reaching repository\n- More\
      \ reliable than custom Python validators\n\nManual run for immediate validation:\n$ SKIP= pre-commit run mintlify-broken-links-check\
      \ --all-files\nOR\n$ make docs-validate-mintlify\nOR\n$ cd docs && npx mintlify broken-links\n\nMigration (2025-11-15):\n\
      - Mintlify CLI is now PRIMARY validator (pre-push + CI)\n- Removed redundant Python validators from pre-push\n- Moved\
      \ from manual to pre-push to catch errors before remote push\n- See: docs-internal/DOCS_VALIDATION_SIMPLIFICATION.md\n"
  - id: validate-adr-index
    name: Validate ADR Index is Up-to-Date
    entry: python -u scripts/docs/generate_adr_index.py --check
    language: system
    files: ^adr/.*\.md$
    pass_filenames: false
    always_run: false
    stages:
    - pre-push
    description: 'Ensures adr/README.md index is up-to-date with all ADR files.


      Validates:

      - All ADRs are listed in the index with correct metadata

      - Categories are accurate and complete

      - No duplicate ADR numbers

      - Index generation instructions are current


      To regenerate: python scripts/generate_adr_index.py


      Regression prevention for REC-001 from documentation audit (2025-11-12).

      '
  - id: check-internal-links
    name: Check Internal Documentation Links (GitHub, ADR, docs-internal)
    entry: uv run --frozen python -u scripts/ci/check-links.py --root-dir . --exclude archive/ reports/ docs/
    language: system
    files: ^(\.github/.*\.md|adr/.*\.md|docs-internal/.*\.md|README\.md|CONTRIBUTING\.md|CHANGELOG\.md)$
    pass_filenames: false
    always_run: false
    stages:
    - pre-push
    description: 'Validates internal documentation links in non-Mintlify markdown files.

      Checks .github/, adr/, docs-internal/, and root markdown files for broken links.

      Excludes docs/ (covered by mintlify-broken-links-check), archive/, and reports/.


      High-priority files checked:

      - .github/*.md (CONTRIBUTING.md, SECURITY.md, etc.)

      - adr/*.md (Architecture Decision Records)

      - docs-internal/*.md (Internal documentation)

      - Root files (README.md, CONTRIBUTING.md, CHANGELOG.md)


      Complements mintlify-broken-links-check which only validates docs/ directory.

      Prevents broken cross-references between ADRs and internal documentation.


      Added: 2025-11-29 (CI gap analysis - broken links in .github/ and adr/ not caught locally)

      '
  # NOTE: validate-deployment-secrets, validate-cors-security, check-hardcoded-credentials,
  # validate-redis-password-required hooks REMOVED (2025-11-25)
  # Reason: Consolidated into run-pre-push-tests hook via (unit or validation) marker
  # Tests in tests/deployment/test_helm_configuration.py are marked as unit tests
  # and run automatically when deployment files change.
  # This reduces pytest invocations from 21 to 1, saving ~4 minutes per pre-push.
  - id: trivy-scan-k8s-manifests
    name: Trivy Security Scan for Kubernetes Manifests
    entry: >
      bash -c 'if ! command -v trivy &> /dev/null; then
      echo "ERROR: trivy required for security scanning.";
      echo "Install via mise: curl https://mise.run | sh && mise install";
      echo "Or: brew install trivy";
      exit 1;
      fi;
      trivy config deployments --severity CRITICAL,HIGH --skip-dirs "**/charts" --exit-code 1 --quiet ||
      (echo "Security vulnerabilities found. Run: trivy config deployments --severity CRITICAL,HIGH --skip-dirs charts"; exit 1)'
    language: system
    files: ^deployments/.*\.(yaml|yml)$
    pass_filenames: false
    always_run: false
    stages:
    - pre-push
    description: 'Scans Kubernetes manifests for security misconfigurations using Trivy.


      Detects issues like:

      - readOnlyRootFilesystem: false (AVD-KSV-0014)

      - Missing security contexts

      - Privileged containers

      - Missing resource limits


      Install Trivy:

      - macOS: brew install trivy

      - Linux: See https://aquasecurity.github.io/trivy/latest/getting-started/installation/


      If Trivy is not installed, the hook will skip scanning (not fail).

      CI/CD environments should have Trivy installed for mandatory scans.


      Regression prevention for: Deploy to GKE Staging failure (Run #19309378657)

      '
  - id: checkov-terraform
    name: Checkov Terraform Security Scan
    entry: >
      bash -c 'if ! command -v checkov &> /dev/null; then
      echo "WARNING: checkov not installed. Skipping Terraform security scan.";
      echo "Install via: pip install checkov or brew install checkov";
      exit 0;
      fi;
      checkov -d terraform/ --framework terraform --quiet --compact \
        --skip-check CKV_TF_1,CKV_TF_2 \
        --output cli || (echo "Checkov found security issues in Terraform. Run: checkov -d terraform/ --framework terraform"; exit 1)'
    language: system
    files: ^terraform/.*\.tf$
    pass_filenames: false
    always_run: false
    stages:
    - pre-push
    description: 'Scans Terraform configurations for security misconfigurations using Checkov.

      Detects issues like:
      - IAM policy with wildcard resources (CKV_AWS_355)
      - IAM policy without constraints (CKV_AWS_290)
      - Missing encryption configurations
      - Overly permissive security groups

      Install Checkov:
      - pip install checkov
      - brew install checkov (macOS)

      Skipped checks:
      - CKV_TF_1: Module source not pinned (we use version constraints)
      - CKV_TF_2: Provider version not pinned (managed in required_providers)

      If Checkov is not installed, the hook will skip scanning (not fail).
      CI/CD environments have Checkov installed for mandatory scans.

      Added: 2025-11-28 (CodeQL gap analysis - PR #121)
      '
  - id: trivy-helm-scan
    name: Trivy Helm Chart Security Scan
    entry: >
      bash -c 'if ! command -v trivy &> /dev/null; then
      echo "WARNING: trivy not installed. Skipping Helm chart security scan.";
      echo "Install via mise: curl https://mise.run | sh && mise install";
      echo "Or: brew install trivy";
      exit 0;
      fi;
      cd deployments/helm/mcp-server-langgraph &&
      trivy config . --severity CRITICAL,HIGH --exit-code 1 --quiet --skip-dirs charts ||
      (echo "Security vulnerabilities found in Helm charts. Run: trivy config deployments/helm/mcp-server-langgraph --severity CRITICAL,HIGH"; exit 1)'
    language: system
    files: ^deployments/helm/.*\.(yaml|yml|tpl)$
    pass_filenames: false
    always_run: false
    stages:
    - pre-push
    description: 'Scans Helm charts (including subcharts) for security misconfigurations.

      Extends trivy-scan-k8s-manifests to cover the helm/ directory and subcharts.
      Uses .trivyignore in deployments/helm/mcp-server-langgraph/ for suppressions.

      Detects issues like:
      - Missing security contexts (KSV118)
      - ConfigMaps with secrets (AVD-KSV-0109)
      - :latest image tags (KSV013)
      - Privileged containers

      Install Trivy:
      - macOS: brew install trivy
      - Linux: See https://aquasecurity.github.io/trivy/latest/getting-started/installation/

      Added: 2025-11-28 (CodeQL gap analysis - PR #121)
      '
  - id: trivy-helm-full-scan
    name: Trivy Helm Full Scan (with subcharts)
    entry: bash scripts/security/scan_helm_templates.sh
    language: system
    files: ^deployments/helm/.*
    pass_filenames: false
    always_run: false
    stages:
    - pre-push
    description: 'Comprehensive Helm chart security scan including all subcharts.

      IMPORTANT: This hook templates the entire Helm chart (including subcharts stored
      as .tgz archives) and scans the rendered YAML files. This catches security issues
      in upstream dependency charts that trivy-helm-scan misses.

      Addresses the CodeQL/Trivy gap where subcharts are stored as compressed .tgz
      files locally but extracted during CI scanning.

      Requires: helm and trivy installed
      Install: brew install helm trivy

      The scan respects suppressions in deployments/helm/mcp-server-langgraph/.trivyignore

      Added: 2025-11-28 (CodeQL gap analysis - PR #121)
      '
  - id: semgrep-security-scan
    name: Semgrep Security Scan (CodeQL Parity)
    entry: >
      bash -c '
        # Find semgrep: prefer venv, fallback to system
        if [ -x ".venv/bin/semgrep" ]; then
          SEMGREP=".venv/bin/semgrep";
        elif command -v semgrep &> /dev/null; then
          SEMGREP="semgrep";
        else
          echo "ERROR: semgrep not installed. This is REQUIRED for security scanning.";
          echo "";
          echo "Install semgrep:";
          echo "  uv sync --group dev   # installs via pyproject.toml";
          echo "  pip install semgrep   # or install directly";
          echo "  brew install semgrep  # or via Homebrew";
          echo "";
          echo "To skip (not recommended): SKIP_SEMGREP=1 git push";
          if [ "${SKIP_SEMGREP:-0}" = "1" ]; then
            echo "WARNING: SKIP_SEMGREP=1 set - skipping security scan (NOT RECOMMENDED)";
            exit 0;
          fi;
          exit 1;
        fi;
        $SEMGREP scan --config auto --error --severity ERROR --quiet src/ scripts/ ||
        (echo "Semgrep found security issues. Run: $SEMGREP scan --config auto src/ scripts/"; exit 1)'
    language: system
    files: ^(src|scripts)/.*\.py$
    pass_filenames: false
    always_run: false
    stages:
    - pre-push
    description: 'Static analysis for Python security issues (CodeQL equivalent).

      REQUIRED: Semgrep must be installed. Install via: uv sync --group dev

      Provides local coverage for security patterns that CodeQL catches in CI:
      - Empty except blocks (py/empty-except equivalent)
      - SQL injection, command injection
      - Hardcoded credentials
      - Unsafe deserialization

      To skip (emergency only): SKIP_SEMGREP=1 git push

      Added: 2025-11-28 (CodeQL gap analysis - PR #121)
      Updated: 2025-11-29 (fail by default, added to pyproject.toml dev deps)
      '
  - id: security-tools-check
    name: Security Tools Check (if ENFORCE_SECURITY_TOOLS=1)
    entry: >
      bash -c 'if [ "${ENFORCE_SECURITY_TOOLS:-0}" = "1" ]; then
        echo "Checking security tools (ENFORCE_SECURITY_TOOLS=1)...";
        missing="";
        command -v trivy >/dev/null || missing="${missing} trivy";
        command -v helm >/dev/null || missing="${missing} helm";
        command -v semgrep >/dev/null || missing="${missing} semgrep";
        if [ -n "${missing}" ]; then
          echo "ERROR: Missing security tools:${missing}";
          echo "Install: brew install trivy helm && pip install semgrep";
          exit 1;
        fi;
        echo "All security tools installed.";
      fi'
    language: system
    always_run: true
    pass_filenames: false
    stages:
    - pre-push
    description: 'Verifies security tools are installed (opt-in for security team).

      Set ENFORCE_SECURITY_TOOLS=1 in your shell profile to enable mandatory checks:
        export ENFORCE_SECURITY_TOOLS=1

      Required tools when enabled:
      - trivy: Kubernetes/Helm security scanning
      - helm: Helm chart templating for full subchart scanning
      - semgrep: Python static security analysis

      CI always runs these checks regardless of this setting.

      Added: 2025-11-28 (CodeQL gap analysis - PR #121)
      '
  - id: check-mermaid-styling
    name: Check Mermaid Diagrams for ColorBrewer2 Set3 Styling
    entry: uv run --frozen python -u scripts/validators/check_mermaid_styling.py
    language: system
    files: ^docs/.*\.mdx$
    pass_filenames: true
    always_run: false
    stages:
    - pre-push
    description: 'Validates Mermaid diagram styling consistency (BLOCKING).

      Enforces:
      - Modern syntax (flowchart TD, not graph TB)
      - ColorBrewer2 Set3 palette colors
      - Required comment marker for styled diagrams
      - Sequence diagram theme initialization

      See: docs/references/mermaid-guide.mdx for standards.
      Moved to pre-push stage 2025-11-30 (enforce diagram standards).

      '
  # NOTE: prevent-local-config-commits hook REMOVED (2025-11-25)
  # Reason: Consolidated into run-pre-push-tests hook via meta marker
  # tests/meta/validation/test_gitignore_validation.py runs with other meta tests
  - id: validate-github-workflows-comprehensive
    name: Validate GitHub Workflows (Comprehensive)
    entry: uv run --frozen python -u scripts/validators/validate_github_workflows_comprehensive.py
    language: system
    files: ^(\.github/workflows/.*\.ya?ml|\.github/actions/.*/action\.yml)$
    pass_filenames: false
    stages:
      - pre-push
    description: "Comprehensive GitHub Actions workflow validation (consolidated):\n\n\
      Replaces: validate-github-workflows + validate-github-action-versions\n\n\
      Validations performed:\n\
      1. YAML syntax validation\n\
      2. Context usage (github.event.* against enabled triggers)\n\
      3. Action version validation (published tags, no invalid versions)\n\
      4. Permissions validation (workflows creating issues have 'issues: write')\n\n\
      Prevents:\n\
      - Using github.event.pull_request.* without pull_request trigger\n\
      - Invalid action versions (e.g., astral-sh/setup-uv@v7.1.1)\n\
      - Missing permissions for issue creation\n\n\
      Consolidation: Part of validator consolidation effort (2025-11-17)\n\
      See: docs-internal/DUPLICATE_VALIDATOR_ANALYSIS_2025-11-16.md\n\
      Test: tests/meta/test_consolidated_workflow_validator.py\n"
  - id: validate-workflow-file-references
    name: Validate Workflow File References
    entry: uv run --frozen python -u scripts/validators/validate_workflow_file_references.py
    language: system
    files: ^\.github/workflows/.*\.ya?ml$
    pass_filenames: false
    stages:
      - pre-commit
    description: "Validates that files referenced in GitHub Actions workflows exist:\n\n\
      Checks:\n\
      1. Script paths (python scripts/, bash scripts/)\n\
      2. Test file paths (pytest tests/)\n\
      3. Path trigger conditions (pull_request/push paths:)\n\
      4. Deployment manifests (deployments/)\n\n\
      Prevents:\n\
      - Script paths that moved but workflows not updated\n\
      - Test paths that reorganized but workflows still reference old locations\n\
      - Missing files that cause silent failures with || true patterns\n\n\
      Example prevented issues:\n\
      - scripts/validate_gke_autopilot_compliance.py → scripts/validators/validate_gke_autopilot_compliance.py\n\
      - tests/regression/test_pod_deployment_regression.py → tests/integration/regression/test_pod_deployment_regression.py\n\n\
      Created: 2025-11-24 (commit 6efbd73f configuration drift remediation)\n\
      See: scripts/validators/validate_workflow_file_references.py\n"
  - id: validate-pytest-fixtures
    name: Validate Pytest Fixture Dependencies
    entry: uv run --frozen python -u scripts/validators/validate_pytest_fixtures.py
    language: system
    files: ^tests/.*\.py$
    pass_filenames: false
    stages:
      - pre-commit
    description: "Validates pytest fixture dependencies before test execution:\n\n\
      Catches errors like:\n\
      - fixture 'test_infrastructure_check' not found\n\
      - Circular fixture dependencies\n\
      - Fixture scope mismatches\n\n\
      Handles:\n\
      - pytest.fixture and pytest_asyncio.fixture decorators\n\
      - Hypothesis @given (keyword and positional args)\n\
      - pytest.mark.parametrize decorators\n\
      - unittest.mock @patch decorators (mock_* patterns)\n\
      - Built-in fixtures (capsys, monkeypatch, tmp_path)\n\
      - Custom fixtures from conftest.py and tests/fixtures/\n\n\
      Prevents:\n\
      - Missing fixture errors at execution time\n\
      - 17 E2E test failures from fixture 'test_infrastructure_check' not found\n\
      - pytest --collect-only doesn't catch these (fixtures resolved at execution)\n\n\
      Created: 2025-11-24 (improved pre-commit validation)\n\
      See: scripts/validators/validate_pytest_fixtures.py\n"
  - id: validate-gke-autopilot-compliance
    name: Validate GKE Autopilot Resource Compliance
    entry: uv run --frozen python -u scripts/validators/validate_gke_autopilot_compliance.py
    language: system
    files: ^deployments/.*\.ya?ml$
    pass_filenames: false
    stages:
    - pre-push
    description: "Validates that Kubernetes manifests comply with GKE Autopilot constraints:\n- CPU limit/request ratio \u2264\
      \ 4.0x\n- Memory limit/request ratio \u2264 4.0x\n- No environment variables with both 'value' and 'valueFrom'\n\nPrevents\
      \ deployment failures and pod creation errors on GKE Autopilot.\n\nRegression prevention for:\n- Run #19310965220: GKE\
      \ Autopilot validation failure\n- Run #19310965206: Deployment validation failure\n- Run #19310965249: Deploy to GKE\
      \ Staging failure\n"
  - id: validate-dependency-injection
    name: Validate Dependency Injection Configuration
    entry: uv run --frozen python -u scripts/validators/validate_dependency_injection.py
    language: system
    pass_filenames: false
    files: ^(src/mcp_server_langgraph/(core/dependencies|core/cache|auth/service_principal)\.py|tests/integration/test_(dependencies_wiring|cache_redis_config)\.py)$
    always_run: false
    stages:
    - pre-push
    description: 'Validates that dependency injection is properly configured to prevent:

      1. Missing Keycloak admin credentials

      2. OpenFGA client created with None store_id

      3. Service principal crashes when OpenFGA disabled

      4. L2 cache ignoring secure Redis settings

      5. Missing critical test coverage

      See ADR-0042 for details on these critical production bugs.

      '
  - id: validate-grafana-dashboards
    name: Validate Grafana Dashboard Best Practices
    entry: uv run --frozen python -u scripts/validation/validate_grafana_dashboards.py
    language: system
    files: ^(monitoring/grafana/dashboards/.*\.json|deployments/helm/.*/dashboards/.*\.json)$
    pass_filenames: false
    always_run: false
    stages:
    - pre-push
    description: "Validates Grafana dashboards against best practices:\n\n\
      Checks:\n\
      1. JSON validity and required fields (uid, title, schemaVersion >= 36)\n\
      2. 24-column grid compliance (no overflow)\n\
      3. graphTooltip configuration (shared crosshair)\n\
      4. Dashboard description (>= 50 chars recommended)\n\
      5. Navigation links with includeVars/keepTime\n\
      6. Panel descriptions for context\n\
      7. Collapsible row structure\n\
      8. timepicker refresh_intervals\n\n\
      Prevents:\n\
      - Grid overflow layout issues\n\
      - Missing descriptions that hinder troubleshooting\n\
      - Navigation links losing time context\n\n\
      Created: 2025-12-11 (Grafana dashboard audit)\n\
      See: scripts/validation/validate_grafana_dashboards.py\n"
  - id: validate-test-fixtures
    name: Validate Test Fixtures for Common Issues
    entry: uv run --frozen python -u scripts/validators/validate_test_fixtures.py
    language: system
    files: ^tests/.*test_.*\.py$
    pass_filenames: true
    always_run: false
    stages:
    - pre-push
    description: 'Validates test fixtures to prevent common failures:

      1. Missing FastAPI dependency overrides (causes 401 errors)

      2. Invalid Ollama model names (missing ollama/ prefix)

      3. Circuit breaker tests without proper isolation markers

      Errors block commits, warnings are informational only.

      See: tests/API_TESTING.md for detailed guidance.

      '
  - id: shellcheck
    name: Shellcheck - Bash Script Linting
    entry: shellcheck
    language: system
    types:
    - shell
    args:
    - -x
    - --severity=warning
    description: 'Validates bash scripts for common errors and best practices.

      Prevents runtime errors like undefined functions, integer comparison issues,

      and improper variable handling. See preview-smoke-tests.sh fixes as examples.

      '
  - id: validate-pytest-markers
    name: Validate Pytest Markers & Placement
    entry: uv run --frozen python -u scripts/validators/validate_pytest_markers.py
    language: system
    pass_filenames: false
    files: ^(tests/.*\.py|pyproject\.toml)$
    exclude: ^tests/(conftest\.py|validation_lib/.*\.py)$
    description: 'Validates pytest marker registration and pytestmark placement.


      1. Checks all pytest.mark.* decorators are registered in pyproject.toml

         (prevents "PytestUnknownMarkWarning" errors)


      2. Validates pytestmark appears AFTER all imports (prevents SyntaxError)


      CODEX FINDING REGRESSION PREVENTION (2025-11-20):

      - Prevents pytestmark inside import blocks causing SyntaxError

      - Uses AST parsing to detect misplaced module-level pytestmark

      - See: docs-internal/PYTESTMARK_GUIDELINES.md for placement rules

      '
  - id: validate-test-collection
    name: Validate Pytest Can Collect All Tests
    # CRITICAL: OTEL_SDK_DISABLED prevents OpenTelemetry initialization during collection
    entry: bash -c 'OTEL_SDK_DISABLED=true uv run --frozen pytest --collect-only tests/ -q --quiet 2>&1 | grep -q "tests collected" || exit 1'
    language: system
    files: ^tests/.*\.py$
    pass_filenames: false
    stages:
      - pre-push
    description: 'Validates that pytest can successfully collect all test files.

      Prevents test collection failures from:

      - SyntaxError in test files

      - ImportError from missing modules

      - Invalid pytest markers


      Runs test collection without executing tests (fast check).


      CODEX FINDING REGRESSION PREVENTION (2025-11-20):

      - Prevents pytestmark inside imports causing collection failure

      - Prevents ImportError from module relocations

      - Ensures test suite integrity before commit


      Regression prevention for commit a57fcc95.

      '
  # NOTE: validate-fixture-organization, regression-prevention-tests hooks REMOVED (2025-11-25)
  # Reason: Consolidated into run-pre-push-tests hook via meta marker
  # tests/meta/test_fixture_organization.py and test_regression_prevention.py run automatically
  - id: detect-dead-test-code
    name: Detect Dead Code in Test Fixtures (Codex P0)
    entry: uv run --frozen python -u scripts/archive/unused/detect_dead_test_code.py tests/
    language: system
    files: ^tests/.*test_.*\.py$
    pass_filenames: false
    always_run: false
    stages:
    - pre-push
    description: "Detects dead code after return statements in pytest fixtures.\nThis code never executes and represents lost\
      \ test coverage.\n\nPattern detected:\n    @pytest.fixture\n    def my_fixture():\n        return value\n\n        #\
      \ Dead code - never executes!\n        assert something\n\nFix: Extract dead code into separate test function with test_\
      \ prefix.\n\nRegression prevention for Codex P0 finding:\n- test_code_generator.py:33-64 had 18 lines of dead code\n\
      - test_server.py:75-99 had 9 lines of dead code\nThese tests never executed, losing critical test coverage.\n\nMeta-test:\
      \ tests/meta/test_codex_regression_prevention.py::TestDeadCodeInFixtures\n"


  - id: check-e2e-completion
    name: Check E2E Test Implementation Progress
    entry: uv run --frozen python -u scripts/validators/check_e2e_completion.py --min-percent 25
    language: system
    pass_filenames: false
    files: ^tests/e2e/test_full_user_journey\.py$
    always_run: false
    stages:
    - manual
    description: "Tracks E2E test implementation progress to prevent regression of\nCodex Finding #1: \"E2E suite effectively\
      \ inert\u201449 scenarios are xfail placeholders\"\n\nMonitors:\n- Total E2E tests vs implemented tests\n- Completion\
      \ percentage (current: 35%, target: 80%)\n- Prevents decrease in implementation progress\n\nMin: 25% | Current: 35%\
      \ | Target: 80%\n"
  - id: check-test-sleep-budget
    name: Monitor Test Wall-Clock Sleep Time Budget
    entry: uv run --frozen python -u scripts/validators/check_test_sleep_budget.py --max-seconds 60 --warn-seconds 45
    language: system
    pass_filenames: false
    files: ^tests/.*test_.*\.py$
    always_run: false
    stages:
    - manual
    description: 'Monitors total wall-clock sleep time across test suite.


      Related to Codex Finding #5: Wall-clock sleeps make suite slow and flaky


      Current status: 36s in active tests (acceptable)

      Budget: 60s max, 45s warning threshold


      Note: Many sleep calls are in skipped tests or testing actual sleep functionality.

      '
  # NOTE: validate-meta-test-quality hook REMOVED (2025-11-25)
  # Reason: Consolidated into run-pre-push-tests hook via meta marker
  # tests/meta/test_property_test_quality.py, test_context_manager_quality.py,
  # test_kubectl_safety.py run automatically with other meta tests
  # NOTE: validate-github-action-versions hook REMOVED (2025-11-17)
  # Consolidated into validate-github-workflows-comprehensive (above)
  # See: docs-internal/DUPLICATE_VALIDATOR_ANALYSIS_2025-11-16.md
  # NOTE: validate-kustomize-builds, validate-network-policies, validate-service-accounts
  # hooks REMOVED (2025-11-25)
  # Reason: Consolidated into run-pre-push-tests hook via unit marker
  # tests/deployment/*.py run automatically when deployment files change

  - id: check-helm-placeholders
    name: Check Helm values for unresolved placeholders
    entry: 'bash -c ''if grep -r "YOUR_.*_PROJECT_ID\|@PROJECT_ID\." deployments/helm/values-*.yaml | grep -v "^#" | grep
      -v "TODO" | grep -v "# For" | grep -v ".local.yaml"; then echo "ERROR: Found unresolved PROJECT_ID placeholders in Helm
      values files."; echo "Use either @DOLLAR{GCP_PROJECT_ID} or actual project IDs."; echo "For deployment-specific values,
      create values-*.local.yaml files."; exit 1; else echo "No dangerous placeholders found"; fi''

      '
    language: system
    pass_filenames: false
    files: ^deployments/helm/values-.*\.(yaml|yml)$
    always_run: false
    stages:
    - pre-push
    description: 'Prevents committing unresolved PROJECT_ID placeholders in Helm values.


      Dangerous patterns blocked:

      - YOUR_STAGING_PROJECT_ID

      - YOUR_GCP_PROJECT_ID

      - @PROJECT_ID.iam.gserviceaccount.com (not using variable substitution)


      Safe patterns allowed:

      - @${GCP_PROJECT_ID}.iam.gserviceaccount.com (variable substitution)

      - vishnu-sandbox-20250310 (actual project ID)

      - Commented placeholders with TODO or "# For" documentation


      Best practice: Create values-*.local.yaml for deployment-specific configs.

      Add *.local.yaml to .gitignore to prevent committing secrets.


      Prevents accidental deployment failures and security issues.

      Regression prevention for Codex findings: values-staging.yaml:108, values-production.yaml:139

      '
  # NOTE: validate-docker-compose-health-checks hook REMOVED (2025-11-25)
  # Reason: Consolidated into run-pre-push-tests hook via unit marker
  # tests/security/test_deployment_security_regression.py runs automatically
  - id: validate-keycloak-config
    name: Validate Keycloak service configuration in docker-compose.test.yml
    entry: uv run --frozen python -u scripts/validators/validate_keycloak_config.py docker/docker-compose.test.yml
    language: system
    files: ^docker/docker-compose\.test\.yml$
    pass_filenames: false
    always_run: false
    description: 'Validates Keycloak service configuration in docker-compose.test.yml (TDD).


      Critical checks:

      - keycloak-test service exists and is uncommented

      - Health check configuration is present

      - Required environment variables are configured (KEYCLOAK_ADMIN, KC_DB, KC_DB_URL, KC_HEALTH_ENABLED)

      - start_period is adequate (60s minimum for Keycloak initialization)


      Prevents regression of Codex Finding #2: Keycloak service unavailable

      causing TestStandardUserJourney::test_01_login failures.


      Trade-off: +60s startup time vs. comprehensive E2E auth testing coverage.


      See: ADR-0053, tests/meta/test_precommit_keycloak_validation.py

      '
  - id: validate-docker-image-contents
    name: Validate Docker image contents in Dockerfile (final-test stage)
    entry: uv run --frozen python -u scripts/validators/validate_docker_image_contents.py docker/Dockerfile
    language: system
    files: ^docker/Dockerfile$
    pass_filenames: false
    always_run: false
    description: 'Validates Docker image contents in Dockerfile (TDD).


      Required COPY commands in final-test stage:

      - src/ (application source code)


      - pyproject.toml (project configuration)


      Excluded (meta-tests run on host, not in Docker):

      - scripts/ (meta-test validation scripts)

      - deployments/ (Kubernetes manifests, Helm charts)


      Prevents regression of Codex Findings #4 & #5:

      - ModuleNotFoundError for ''scripts'' module

      - FileNotFoundError for /app/deployments


      Design rationale:

      - Integration tests run IN Docker: need src/, tests/, pyproject.toml

      - Meta-tests run ON host: need full repo (scripts/, deployments/)

      - Separation prevents Docker image bloat


      See: ADR-0053, tests/meta/test_precommit_docker_image_validation.py

      '
  - id: helm-lint
    name: Helm Lint Validation
    entry: >
      bash -c 'if ! command -v helm >/dev/null 2>&1; then
      echo "ERROR: helm required for Helm chart validation.";
      echo "Install via mise: curl https://mise.run | sh && mise install";
      echo "Or: https://helm.sh/docs/intro/install/";
      exit 1; fi;
      echo "Building Helm dependencies..." &&
      helm dependency build deployments/helm/mcp-server-langgraph 2>/dev/null || true &&
      helm lint deployments/helm/mcp-server-langgraph'
    language: system
    files: ^deployments/helm/.*\.(yaml|yml)$
    pass_filenames: false
    stages:
    - pre-push
    description: 'Validates Helm chart passes lint checks.


      CLI Availability Guard: Gracefully skips if helm is not installed.


      Prevents:

      - Hyphenated key parsing errors (e.g., .Values.kube-prometheus-stack.enabled)

      - Template syntax errors

      - Invalid Kubernetes resource schemas

      - Missing required values


      Fix: Use index .Values "kube-prometheus-stack" "enabled" for hyphenated keys


      Regression prevention for Codex Finding #1 (P0 Blocker)

      '
  - id: validate-helm-chart-deps
    name: Validate Helm Chart Dependencies Complete
    entry: >
      bash -c 'if ! command -v helm >/dev/null 2>&1; then
      echo "SKIP: helm not installed, cannot validate chart dependencies.";
      exit 0; fi;
      CHART_DIR="deployments/helm/mcp-server-langgraph";
      EXPECTED_CHARTS=7;
      if [ ! -d "$CHART_DIR/charts" ]; then
      echo "ERROR: charts/ directory not found. Run: helm dependency build $CHART_DIR";
      exit 1; fi;
      ACTUAL_CHARTS=$(ls "$CHART_DIR/charts/"*.tgz 2>/dev/null | wc -l);
      if [ "$ACTUAL_CHARTS" -ne "$EXPECTED_CHARTS" ]; then
      echo "ERROR: Helm chart dependencies incomplete: $ACTUAL_CHARTS/$EXPECTED_CHARTS";
      echo "Expected: openfga, postgresql, redis, keycloak, grafana, jaeger, kube-prometheus-stack";
      echo "Run: helm dependency build $CHART_DIR";
      exit 1; fi;
      echo "✅ All $ACTUAL_CHARTS Helm chart dependencies present"'
    language: system
    files: ^deployments/helm/.*\.(yaml|yml)$
    pass_filenames: false
    stages:
    - pre-push
    description: 'Validates ALL Helm chart dependencies are downloaded.

      CI PARITY FIX (2025-12-11): Prevents corrupted partial cache issues.

      Checks that charts/ contains all 7 expected charts (openfga, postgresql,
      redis, keycloak, grafana, jaeger, kube-prometheus-stack).

      Run helm dependency build deployments/helm/mcp-server-langgraph to fix.

      See: .claude/plans/purrfect-dazzling-breeze.md for root cause analysis.

      '
  - id: validate-cloud-overlays
    name: Validate Cloud Overlays Build Successfully
    entry: >
      bash -c 'if ! command -v kubectl >/dev/null 2>&1; then
      echo "ERROR: kubectl required for Kustomize validation.";
      echo "Install via mise: curl https://mise.run | sh && mise install";
      echo "Or: https://kubernetes.io/docs/tasks/tools/";
      exit 1; fi;
      kubectl kustomize deployments/kubernetes/overlays/aws &&
      kubectl kustomize deployments/kubernetes/overlays/gcp &&
      kubectl kustomize deployments/kubernetes/overlays/azure'
    language: system
    files: ^deployments/kubernetes/overlays/(aws|gcp|azure)/.*\.(yaml|yml)$
    pass_filenames: false
    stages:
    - pre-push
    description: 'Validates cloud-specific Kustomize overlays build without errors.


      CLI Availability Guard: Gracefully skips if kubectl is not installed.


      Prevents:

      - ConfigMap generator issues with behavior: replace

      - Missing ConfigMaps or resources

      - YAML syntax errors in cloud configs


      Regression prevention for Codex Finding #2 (P0 Blocker)

      '
  - id: validate-no-placeholders
    name: Check for Placeholders in Production Overlays
    entry: >
      bash -c 'if command -v kubectl >/dev/null 2>&1; then
      kubectl kustomize deployments/overlays/production-gke | grep -E "PLACEHOLDER_|PRODUCTION_DOMAIN" && exit 1 || exit 0;
      else echo "Skipping: kubectl not installed (install from https://kubernetes.io/docs/tasks/tools/)";
      exit 0; fi'
    language: system
    files: ^deployments/overlays/production-gke/.*\.(yaml|yml)$
    pass_filenames: false
    stages:
    - pre-push
    description: 'Validates production overlays don''t contain unresolved placeholders.


      Prevents:

      - PLACEHOLDER_GCP_PROJECT_ID in service accounts

      - PLACEHOLDER_SET_VIA_ENV in environment variables

      - PRODUCTION_DOMAIN in configuration


      Ensures production deployments have valid, runtime-ready configuration.


      Regression prevention for Codex Finding #3 (P0 Blocker)

      '


  - id: check-async-mock-configuration
    name: Check AsyncMock Configuration (prevent authorization bypass)
    entry: uv run --frozen python -u scripts/validators/check_async_mock_configuration.py
    language: system
    files: ^tests/.*test_.*\.py$
    pass_filenames: false
    always_run: false
    stages:
    - pre-commit
    description: 'Validates that all AsyncMock instances have explicit return_value or side_effect configuration.


      SECURITY CRITICAL: Unconfigured AsyncMock returns truthy values, causing authorization

      checks to incorrectly pass. This was the root cause of SCIM security bug (commit abb04a6a).


      Issue prevented:

      - Unconfigured AsyncMock() returns <AsyncMock> (truthy) instead of False

      - Authorization checks like "if await openfga.check_permission()" evaluate to True

      - Security controls bypassed, granting access when it should be denied

      - Tests pass incorrectly, hiding authorization bugs


      Required pattern:

      - Authorization denial: mock.check_permission.return_value = False

      - Authorization grant: mock.check_permission.return_value = True

      - Void functions: mock.write_tuples.return_value = None

      - Exceptions: mock.method.side_effect = Exception("error")


      Current status: 65 unconfigured high-risk instances (authorization/permission checks)

      Future: Will move to pre-push stage after fixing all violations


      See: tests/ASYNC_MOCK_GUIDELINES.md for complete guide

      Meta-test: tests/meta/test_async_mock_configuration.py validates this

      '
  - id: check-asyncmock-instantiation
    name: Check AsyncMock Instantiation (prevent class assignment)
    entry: uv run --frozen python -u scripts/validators/check_asyncmock_usage.py
    language: system
    files: ^tests/.*test_.*\.py$
    exclude: ^tests/meta/test_asyncmock_validation\.py$
    pass_filenames: true
    always_run: false
    description: 'Prevents AsyncMock class assignment instead of instance creation.

      Issue prevented:

      - Assigning AsyncMock class instead of AsyncMock() instance

      - Causes "object AsyncMock can''t be used in ''await'' expression" errors

      - Often appears with noqa comments documenting intended config but not applied


      Required pattern:

      - CORRECT: mock.method = AsyncMock(return_value=1)

      - CORRECT: mock.method = AsyncMock()

      - WRONG: mock.method = AsyncMock  # noqa: async-mock-config(return_value=1)


      This hook catches the specific bug where developers put the configuration

      in a noqa comment but forget to actually instantiate the AsyncMock.


      See: tests/unit/health/test_database_checks.py (fixed instances)

      Meta-test: tests/meta/test_asyncmock_validation.py validates this

      '
  - id: validate-test-isolation
    name: Validate Test Isolation for Pytest-xdist
    entry: uv run --frozen python -u scripts/validators/validate_test_isolation.py tests/
    language: system
    # Pattern expanded (P1-2 - 2025-11-27): Now includes conftest.py (fixture definitions affect isolation)
    files: ^tests/(.*test_.*\.py|.*conftest\.py)$
    pass_filenames: false
    always_run: false
    stages:
    - pre-push
    description: 'Validates that test files follow best practices for pytest-xdist parallel execution.


      Prevents regression of bug fixed in commit 079e82e where async dependencies were

      overridden with sync lambda functions, causing intermittent 401 authentication failures.


      Critical validations:

      - Async dependencies MUST be overridden with async functions (not lambdas)

      - FastAPI dependency_overrides.clear() called in fixture teardown

      - Test classes use @pytest.mark.xdist_group marker for related tests

      - teardown_method() includes gc.collect() to prevent memory leaks


      Without these patterns:

      - Tests pass when run with pytest -xvs (single process)

      - Tests fail intermittently with pytest -n auto (parallel workers)

      - Difficult to debug due to race conditions


      See: tests/PYTEST_XDIST_BEST_PRACTICES.md for complete guidance

      Regression tests: tests/regression/test_pytest_xdist_isolation.py

      '
  # NOTE: validate-test-dependencies hook REMOVED (2025-11-25)
  # Reason: Consolidated into run-pre-push-tests hook via unit marker
  # tests/regression/test_dev_dependencies.py runs automatically
  - id: validate-workflow-test-deps
    name: Validate Workflow Test Dependencies
    entry: uv run --frozen python -u scripts/validators/validate_workflow_test_deps.py
    language: system
    files: ^\.github/workflows/.*\.ya?ml$
    pass_filenames: false
    always_run: false
    stages:
    - pre-push
    description: "Validates that GitHub Actions workflows installing dependencies for tests\ninclude the required 'dev' extras.\n\
      \nPrevents the configuration issue that caused 10 CI failures on 2025-11-12:\n- Workflows ran pytest but didn't install\
      \ dev extras\n- Missing docker/kubernetes packages broke test imports\n- Root cause: setup-python-deps used without\
      \ 'dev' in extras parameter\n\nChecks:\n- Workflows using setup-python-deps + pytest must install 'dev' extras\n- Skips\
      \ workflows using uv run (auto-installs) or other methods\n- Only validates workflows that explicitly use setup-python-deps\
      \ action\n\nQuick fix: Add or update 'extras' parameter in setup-python-deps step:\n  - uses: ./.github/actions/setup-python-deps\n\
      \    with:\n      extras: 'dev'\n\nRegression prevention for commit 7b51437 (2025-11-12)\n\
      See: scripts/validators/validate_workflow_test_deps.py for implementation\n"
  # NOTE: validate-fixture-scopes hook REMOVED (2025-11-25)
  # Reason: Consolidated into run-pre-push-tests hook via meta marker
  # tests/meta/test_fixture_validation.py runs automatically with other meta tests
  - id: validate-minimum-coverage
    name: "Validate Minimum Test Coverage Threshold (\u2265 64%)"
    # CRITICAL: OTEL_SDK_DISABLED prevents OpenTelemetry initialization in pytest
    entry: bash -c 'OTEL_SDK_DISABLED=true uv run --frozen pytest tests/meta/test_coverage_enforcement.py -v --tb=short'
    language: system
    pass_filenames: false
    files: ^(src/.*\.py|tests/.*\.py|pyproject\.toml)$
    always_run: false
    stages:
    - manual
    description: "Prevents coverage regression by enforcing minimum 64% threshold.\n\nValidates that:\n- Overall test coverage\
      \ \u2265 64% (CI threshold)\n- Coverage doesn't drop from Phase 1 baseline (65.78%)\n- All new code is adequately tested\n\
      \nCoverage targets:\n- Minimum: 64% (MUST NOT DROP BELOW)\n- Current: 65.78% (after Phase 1 improvements)\n- Target:\
      \ 80% (Codex recommendation)\n- Excellent: 90%+\n\nPhase 1 achievements:\n- prometheus_client.py: 44% \u2192 87% (+43%)\n\
      - budget_monitor.py: 47% \u2192 81% (+34%)\n- cost_api.py: 55% \u2192 91% (+36%)\n\nTo diagnose coverage issues:\n1.\
      \ Run: pytest --cov --cov-report=html\n2. Open: htmlcov/index.html\n3. Identify modules with low coverage\n4. Write\
      \ tests for uncovered code paths\n\nRegression prevention for Phase 1 (2025-11-15)\nSee: tests/meta/test_coverage_enforcement.py\
      \ for implementation\n"
  # REMOVED: validate-test-suite-performance and detect-slow-unit-tests hooks
  # Reason: YAGNI - These spawned subprocess pytest runs that were skipped everywhere
  # (CI, pre-push, xdist). Use 'pytest --durations=50' in CI artifacts instead.
  # Removed: 2025-11-30 as part of test suite modernization
  - id: validate-pytest-config
    name: Validate Pytest Configuration
    entry: uv run --frozen python -u scripts/validators/validate_pytest_config.py
    language: system
    files: ^pyproject\.toml$
    pass_filenames: false
    always_run: false
    stages:
    - pre-push
    description: "Validates pytest configuration in pyproject.toml."

  - id: check-test-memory-safety
    name: Check Test Memory Safety
    entry: uv run --frozen python -u scripts/validators/check_test_memory_safety.py
    language: system
    files: ^tests/.*\.py$
    pass_filenames: true
    always_run: false
    stages:
    - pre-push
    description: "Validates memory safety in tests (gc.collect in teardown)."

  - id: check-test-naming
    name: Check Test Naming Conventions
    entry: uv run --frozen python -u scripts/validators/check_test_naming.py
    language: system
    files: ^tests/.*\.py$
    pass_filenames: true
    always_run: false
    stages:
    - pre-commit
    description: 'Validates test naming conventions.

      Test files must use test_*.py pattern.

      Test functions must use descriptive names: test_<function>_<scenario>_<expected_result>.

      Prevents generic names like test_1, test_case_1, test_function.

      See: CLAUDE.md for complete test naming conventions.

      '

  - id: validate-test-ids
    name: Validate Test IDs (xdist isolation)
    entry: uv run --frozen python -u scripts/validators/validate_test_ids.py
    language: system
    files: ^tests/.*\.py$
    pass_filenames: true
    always_run: false
    stages:
    - pre-push
    description: "Validates that integration tests use worker-safe ID helpers."

  - id: check-test-environment-isolation
    name: Check Test Environment Isolation
    entry: uv run --frozen python -u scripts/validators/check_test_environment_isolation.py
    language: system
    files: ^tests/.*\.py$
    pass_filenames: true
    always_run: false
    stages:
    - pre-push
    description: 'Detects direct os.environ mutations in test files.

      Prevents environment variable pollution in pytest-xdist workers.

      Suggests using monkeypatch.setenv() or centralized fixtures:
      - disable_auth_skip: For MCP_SKIP_AUTH=false
      - isolated_environment: For general env isolation

      References:
      - tests/meta/test_environment_isolation_enforcement.py
      - tests/conftest.py (disable_auth_skip, isolated_environment)

      '

- repo: https://github.com/antonbabenko/pre-commit-terraform
  rev: v1.96.2
  hooks:
  - id: terraform_fmt
    name: Terraform format
    description: Format Terraform files
    files: \.tf$
  - id: terraform_validate
    name: Terraform validate
    description: Validate Terraform syntax
    files: \.tf$
    args:
    - --hook-config=--retry-once-with-cleanup=true
    - --tf-init-args=-backend=false
    stages:
    - pre-push
