name: Quality Tests

on:
  pull_request:
    branches: [main]
  push:
    branches: [main]
  schedule:
    # Run weekly on Sunday at midnight
    - cron: '0 0 * * 0'

permissions:
  contents: read
  pull-requests: write

jobs:
  property-tests:
    name: Property-Based Tests
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .
          pip install -r requirements-pinned.txt
          pip install -r requirements-test.txt

      - name: Run property-based tests
        run: |
          pytest -m property -v --tb=short
        timeout-minutes: 15

      - name: Upload property test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: property-test-results
          path: |
            .hypothesis/
            test-results/

  contract-tests:
    name: Contract Tests
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .
          pip install -r requirements-pinned.txt
          pip install -r requirements-test.txt

      - name: Generate OpenAPI schema
        run: |
          python scripts/validation/validate_openapi.py || true

      - name: Run contract tests
        run: |
          pytest -m contract -v --tb=short

      - name: Upload OpenAPI schema
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: openapi-schema
          path: docs/api/openapi.json

  regression-tests:
    name: Performance Regression Tests
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .
          pip install -r requirements-pinned.txt
          pip install -r requirements-test.txt

      - name: Run regression tests
        run: |
          pytest -m regression -v --tb=short

      - name: Check for performance regressions
        run: |
          echo "Comparing against baseline metrics..."
          # Results are checked within the tests themselves

      - name: Upload regression results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: regression-results
          path: |
            tests/regression/
            .benchmarks/

  quality-summary:
    name: Quality Summary
    runs-on: ubuntu-latest
    needs: [property-tests, contract-tests, regression-tests]
    if: always()

    steps:
      - name: Check quality test results
        run: |
          echo "## Quality Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- Property Tests: ${{ needs.property-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Contract Tests: ${{ needs.contract-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Regression Tests: ${{ needs.regression-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ "${{ needs.property-tests.result }}" = "success" ] && \
             [ "${{ needs.contract-tests.result }}" = "success" ] && \
             [ "${{ needs.regression-tests.result }}" = "success" ]; then
            echo "✅ All quality tests passed!" >> $GITHUB_STEP_SUMMARY
            exit 0
          else
            echo "⚠️ Some quality tests failed" >> $GITHUB_STEP_SUMMARY
            exit 1
          fi
